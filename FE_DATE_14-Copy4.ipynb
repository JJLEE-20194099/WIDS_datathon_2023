{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10ca2220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import seaborn as sns \n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, BaggingRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from scipy.stats import norm\n",
    "import copy\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from catboost import CatBoostRegressor, Pool, metrics, cv\n",
    "import xgboost as xgb\n",
    "from scipy.stats import gmean\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8a635f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_dict = {\n",
    "    \"1\": \"BSk\",\n",
    "    \"9\": \"Dfb\",\n",
    "    \"4\": \"Cfa\",\n",
    "    \"7\": \"Csb\",\n",
    "    \"8\": \"Dfa\",\n",
    "    \"3\": \"BWk\",\n",
    "    \"10\": \"Dfc\",\n",
    "    \"2\": \"BWh\",\n",
    "    \"6\": \"Csa\",\n",
    "    \"11\": \"Dsb\",\n",
    "    \"0\": \"BSh\",\n",
    "    \"5\": \"Cfb\",\n",
    "    \"12\": \"Dsc\",\n",
    "    \"13\": \"Dwa\",\n",
    "    \"14\": \"Dwb\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08445877",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['contest-wind-h500-14d__wind-hgt-500',\n",
    " 'contest-slp-14d__slp',\n",
    " 'nmme-tmp2m-34w__ccsm3', \n",
    " 'elevation__elevation',\n",
    " 'lon',\n",
    " 'contest-prwtr-eatm-14d__prwtr',\n",
    " 'lat',\n",
    " 'climateregions__climateregion',\n",
    " 'contest-pres-sfc-gauss-14d__pres',\n",
    " 'season_sin',\n",
    " 'day_of_year_sin',\n",
    " 'contest-precip-14d__precip',\n",
    " 'contest-wind-uwnd-250-14d__wind-uwnd-250',\n",
    " 'nmme-prate-34w__cfsv2',\n",
    " 'nmme-prate-34w__nasa',\n",
    " 'nmme-prate-56w__gfdlflora',\n",
    " 'wind-uwnd-250-2010-7',\n",
    " 'contest-wind-vwnd-925-14d__wind-vwnd-925',\n",
    " 'nmme-prate-34w__nmmemean',\n",
    " 'nmme0-prate-34w__ccsm30',\n",
    " 'contest-wind-h850-14d__wind-hgt-850',\n",
    " 'contest-wind-uwnd-925-14d__wind-uwnd-925',\n",
    " 'nmme0-prate-56w__cfsv20',\n",
    " 'nmme-prate-34w__cancm3',\n",
    " 'contest-rhum-sig995-14d__rhum',\n",
    " 'nmme-prate-34w__gfdlflorb',\n",
    " 'wind-hgt-850-2010-4',\n",
    " 'contest-wind-vwnd-250-14d__wind-vwnd-250',\n",
    " 'wind-hgt-100-2010-2',\n",
    " 'wind-uwnd-250-2010-18',\n",
    " 'wind-hgt-10-2010-5',\n",
    " 'wind-uwnd-250-2010-15',\n",
    " 'wind-uwnd-250-2010-4',\n",
    " 'nmme0-prate-56w__nasa0',\n",
    " 'nmme0-prate-34w__cfsv20',\n",
    " 'wind-vwnd-250-2010-10',\n",
    " 'contest-wind-h10-14d__wind-hgt-10',\n",
    " 'wind-uwnd-925-2010-15',\n",
    " 'wind-vwnd-250-2010-3',\n",
    " 'nmme-prate-34w__cancm4',\n",
    " 'sst-2010-4',\n",
    " 'nmme0-prate-56w__ccsm30',\n",
    " 'wind-uwnd-250-2010-16',\n",
    " 'nmme0-prate-34w__gfdl0',\n",
    " 'nmme0-prate-56w__cancm40',\n",
    " 'sst-2010-1',\n",
    " 'sst-2010-3',\n",
    " 'wind-uwnd-250-2010-14',\n",
    " 'nmme0-prate-34w__gfdlflora0',\n",
    " 'nmme-prate-34w__gfdl',\n",
    " 'wind-hgt-850-2010-9',\n",
    " 'wind-vwnd-250-2010-1',\n",
    " 'sst-2010-5',\n",
    " 'cancm30',\n",
    " 'nmme-prate-34w__ccsm4',\n",
    " 'nmme0-prate-34w__nasa0',\n",
    " 'wind-hgt-500-2010-9',\n",
    " 'nmme0-prate-34w__cancm30',\n",
    " 'wind-vwnd-250-2010-13',\n",
    " 'wind_diff',\n",
    " 'wind_diff_min',\n",
    " 'wind_diff_min_month',\n",
    " 'wind_diff_month',\n",
    " 'diff_slp_first',\n",
    " 'diff_wind_first',\n",
    " 'diff_precip_first',\n",
    " 'diff_sst_10_first',\n",
    " 'diff_sst_10_min',\n",
    " 'diff_sst_10_max',\n",
    " 'range_sst_10',\n",
    " 'scale_sst_10',\n",
    " 'diff_sst_9_first',\n",
    " 'diff_sst_9_min',\n",
    " 'diff_sst_9_max',\n",
    " 'range_sst_9',\n",
    " 'scale_sst_9',\n",
    " 'diff_sst_8_first',\n",
    " 'diff_sst_8_min',\n",
    " 'diff_sst_8_max',\n",
    " 'range_sst_8',\n",
    " 'scale_sst_8',\n",
    " 'diff_sst_7_first',\n",
    " 'diff_sst_7_min',\n",
    " 'diff_sst_7_max',\n",
    " 'range_sst_7',\n",
    " 'scale_sst_7',\n",
    " 'diff_sst_6_first',\n",
    " 'diff_sst_6_min',\n",
    " 'diff_sst_6_max',\n",
    " 'range_sst_6',\n",
    " 'scale_sst_6',\n",
    " 'diff_sst_1_first',\n",
    " 'diff_sst_1_min',\n",
    " 'diff_sst_1_max',\n",
    " 'range_sst_1',\n",
    " 'scale_sst_1',\n",
    " 'diff_sst_2_first',\n",
    " 'diff_sst_2_min',\n",
    " 'diff_sst_2_max',\n",
    " 'range_sst_2',\n",
    " 'scale_sst_2',\n",
    " 'diff_sst_3_first',\n",
    " 'diff_sst_3_min',\n",
    " 'diff_sst_3_max',\n",
    " 'range_sst_3',\n",
    " 'scale_sst_3',\n",
    " 'diff_sst_4_first',\n",
    " 'diff_sst_4_min',\n",
    " 'diff_sst_4_max',\n",
    " 'range_sst_4',\n",
    " 'scale_sst_4',\n",
    " 'diff_sst_5_first',\n",
    " 'diff_sst_5_min',\n",
    " 'diff_sst_5_max',\n",
    " 'range_sst_5',\n",
    " 'scale_sst_5',\n",
    " 'diff_pres_1_first',\n",
    " 'diff_pres_1_min',\n",
    " 'diff_pres_1_max',\n",
    " 'range_pres_1',\n",
    " 'scale_pres_1',\n",
    " 'diff_ccsm3_month_1_first',\n",
    " 'diff_ccsm3_month_1_min',\n",
    " 'diff_ccsm3_month_1_max',\n",
    " 'range_ccsm3_month_1',\n",
    " 'scale_ccsm3_month_1',\n",
    " 'diff_sst_1_month_1_first',\n",
    " 'diff_sst_1_month_1_min',\n",
    " 'diff_sst_1_month_1_max',\n",
    " 'range_sst_1_month_1',\n",
    " 'scale_sst_1_month_1',\n",
    " 'sst_1_lag_1',\n",
    " 'sst_5_lag_1',\n",
    " 'sst_4_lag_1',\n",
    " 'sst_1_lag_1_season',\n",
    " 'sst_5_lag_1_season',\n",
    " 'sst_4_lag_1_season']\n",
    "\n",
    "target=[\"contest-tmp2m-14d__tmp2m\"]\n",
    "\n",
    "slp_col = 'contest-slp-14d__slp'\n",
    "ccsm3_col = 'nmme-tmp2m-34w__ccsm3'\n",
    "pres_col = 'contest-pres-sfc-gauss-14d__pres'\n",
    "precip_col = 'contest-precip-14d__precip'\n",
    "poten_col = 'contest-pevpr-sfc-gauss-14d__pevpr'\n",
    "rhum_col = 'contest-rhum-sig995-14d__rhum'\n",
    "elevation_col = 'elevation__elevation'\n",
    "wind_col_500 = 'contest-wind-h500-14d__wind-hgt-500'\n",
    "sst_1_col = 'sst-2010-1'\n",
    "sst_5_col = 'sst-2010-5'\n",
    "sst_3_col = 'sst-2010-3'\n",
    "sst_4_col = 'sst-2010-4'\n",
    "sst_6_col = 'sst-2010-6'\n",
    "sst_7_col = 'sst-2010-7'\n",
    "sst_8_col = 'sst-2010-8'\n",
    "sst_9_col = 'sst-2010-9'\n",
    "sst_10_col = 'sst-2010-10'\n",
    "group_cols = ['startdate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aff53ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./df_fe_5_diag_pos_neigh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07373b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_features_5 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_5 = sst_features_5 + [f'sst_{i}_neigh_5_mean', f'sst_{i}_neigh_5_min', f'sst_{i}_neigh_5_max']\n",
    "\n",
    "sst_features_5_diag_11 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_5_diag_11 = sst_features_5_diag_11 + [f'sst_{i}_neigh_5_diag_11_mean', f'sst_{i}_neigh_5_diag_11_min', f'sst_{i}_neigh_5_diag_11_max']\n",
    "\n",
    "\n",
    "sst_features_5_diag_01 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_5_diag_01 = sst_features_5_diag_01 + [f'sst_{i}_neigh_5_diag_01_mean', f'sst_{i}_neigh_5_diag_01_min', f'sst_{i}_neigh_5_diag_01_max']\n",
    "\n",
    "sst_features_5_diag_10 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_5_diag_10 = sst_features_5_diag_10 + [f'sst_{i}_neigh_5_diag_10_mean', f'sst_{i}_neigh_5_diag_10_min', f'sst_{i}_neigh_5_diag_10_max']\n",
    "\n",
    "sst_features_5_diag_00 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_5_diag_00 = sst_features_5_diag_00 + [f'sst_{i}_neigh_5_diag_00_mean', f'sst_{i}_neigh_5_diag_00_min', f'sst_{i}_neigh_5_diag_00_max']\n",
    "\n",
    "\n",
    "sst_features_5_diag_pos = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_5_diag_pos = sst_features_5_diag_pos + [f'sst_{i}_neigh_5_diag_pos_mean', f'sst_{i}_neigh_5_diag_pos_min', f'sst_{i}_neigh_5_diag_pos_max']\n",
    "\n",
    "sst_features_5 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_5 = sst_features_5 + [f'sst_{i}_neigh_5_mean', f'sst_{i}_neigh_5_min', f'sst_{i}_neigh_5_max']\n",
    "\n",
    "sst_features_5_lon_neg = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_5_lon_neg = sst_features_5_lon_neg + [f'sst_{i}_neigh_5_lon_neg_mean', f'sst_{i}_neigh_5_lon_neg_min', f'sst_{i}_neigh_5_lon_neg_max']\n",
    "\n",
    "sst_features_5_lat_neg = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_5_lat_neg = sst_features_5_lat_neg + [f'sst_{i}_neigh_5_lat_neg_mean', f'sst_{i}_neigh_5_lat_neg_min', f'sst_{i}_neigh_5_lat_neg_max']\n",
    "\n",
    "\n",
    "sst_features_5_lat_pos = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_5_lat_pos = sst_features_5_lat_pos + [f'sst_{i}_neigh_5_lat_pos_mean', f'sst_{i}_neigh_5_lat_pos_min', f'sst_{i}_neigh_5_lat_pos_max']\n",
    "\n",
    "sst_features_5_lon_pos = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_5_lon_pos = sst_features_5_lon_pos + [f'sst_{i}_neigh_5_lon_pos_mean', f'sst_{i}_neigh_5_lon_pos_min', f'sst_{i}_neigh_5_lon_pos_max']\n",
    "\n",
    "sst_features_5_diag_pos = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_5_diag_pos = sst_features_5_diag_pos + [f'sst_{i}_neigh_5_diag_pos_mean', f'sst_{i}_neigh_5_diag_pos_min', f'sst_{i}_neigh_5_diag_pos_max']\n",
    "\n",
    "sst_features_5_diag_neg1 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_5_diag_neg1 = sst_features_5_diag_neg1 + [f'sst_{i}_neigh_5_diag_neg1_mean', f'sst_{i}_neigh_5_diag_neg1_min', f'sst_{i}_neigh_5_diag_neg1_max']\n",
    "\n",
    "\n",
    "sst_features_time_5 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_time_5 = sst_features_time_5 + [f'sst_{i}_time_5_mean', f'sst_{i}_time_5_min', f'sst_{i}_time_5_max']\n",
    "\n",
    "sst_features_time_5_pos= []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_time_5_pos= sst_features_time_5_pos+ [f'sst_{i}_time_5_pos_mean', f'sst_{i}_time_5_pos_min', f'sst_{i}_time_5_pos_max']\n",
    "\n",
    "sst_features_time_7 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_time_7 = sst_features_time_7 + [f'sst_{i}_time_7_mean', f'sst_{i}_time_7_min', f'sst_{i}_time_7_max']\n",
    "\n",
    "\n",
    "sst_features_time_14 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_time_14 = sst_features_time_14 + [f'sst_{i}_time_14_mean', f'sst_{i}_time_14_min', f'sst_{i}_time_14_max']\n",
    "\n",
    "sst_features_time_9 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_time_9 = sst_features_time_9 + [f'sst_{i}_time_9_mean', f'sst_{i}_time_9_min', f'sst_{i}_time_9_max']\n",
    "\n",
    "\n",
    "sst_features_time_11 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_time_11 = sst_features_time_11 + [f'sst_{i}_time_11_mean', f'sst_{i}_time_11_min', f'sst_{i}_time_11_max']\n",
    "\n",
    "sst_features_11 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_11 = sst_features_11 + [f'sst_{i}_neigh_11_mean', f'sst_{i}_neigh_11_min', f'sst_{i}_neigh_11_max']\n",
    "\n",
    "sst_features_3 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_3 = sst_features_3 + [f'sst_{i}_neigh_3_mean', f'sst_{i}_neigh_3_min', f'sst_{i}_neigh_3_max']\n",
    "\n",
    "sst_features_7 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_7 = sst_features_7 + [f'sst_{i}_neigh_7_mean', f'sst_{i}_neigh_7_min', f'sst_{i}_neigh_7_max']\n",
    "\n",
    "sst_features_5_lat = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_5_lat = sst_features_5_lat + [f'sst_{i}_neigh_5_lat_mean', f'sst_{i}_neigh_5_lat_min', f'sst_{i}_neigh_5_lat_max']\n",
    "\n",
    "sst_features_5_lon = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_5_lon = sst_features_5_lon + [f'sst_{i}_neigh_5_lon_mean', f'sst_{i}_neigh_5_lon_min', f'sst_{i}_neigh_5_lon_max']\n",
    "\n",
    "sst_features_9_lon = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_9_lon = sst_features_9_lon + [f'sst_{i}_neigh_9_lon_mean', f'sst_{i}_neigh_9_lon_min', f'sst_{i}_neigh_9_lon_max']\n",
    "\n",
    "sst_features_11_lon = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_11_lon = sst_features_11_lon + [f'sst_{i}_neigh_11_lon_mean', f'sst_{i}_neigh_11_lon_min', f'sst_{i}_neigh_11_lon_max']\n",
    "\n",
    "sst_features_15_lon = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_15_lon = sst_features_15_lon + [f'sst_{i}_neigh_15_lon_mean', f'sst_{i}_neigh_15_lon_min', f'sst_{i}_neigh_15_lon_max']\n",
    "\n",
    "sst_features_11_lat = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_11_lat = sst_features_11_lat + [f'sst_{i}_neigh_11_lat_mean', f'sst_{i}_neigh_11_lat_min', f'sst_{i}_neigh_11_lat_max']\n",
    "\n",
    "sst_features_9_lat = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_9_lat = sst_features_9_lat + [f'sst_{i}_neigh_9_lat_mean', f'sst_{i}_neigh_9_lat_min', f'sst_{i}_neigh_9_lat_max']\n",
    "    \n",
    "sst_features_9 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_9 = sst_features_9 + [f'sst_{i}_neigh_9_mean', f'sst_{i}_neigh_9_min', f'sst_{i}_neigh_9_max']\n",
    "\n",
    "sst_features_13 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_13 = sst_features_13 + [f'sst_{i}_neigh_13_mean', f'sst_{i}_neigh_13_min', f'sst_{i}_neigh_13_max']\n",
    "\n",
    "\n",
    "poten_feature_5 = ['poten_neigh_5_mean', 'poten_neigh_5_min', 'poten_neigh_5_max']\n",
    "poten_feature_time_5 = ['poten_time_5_mean', 'poten_time_5_min', 'poten_time_5_max']\n",
    "poten_feature_time_5_pos = ['poten_time_5_pos_mean', 'poten_time_5_pos_min', 'poten_time_5_pos_max']\n",
    "poten_feature_time_7 = ['poten_time_7_mean', 'poten_time_7_min', 'poten_time_7_max']\n",
    "poten_feature_time_11 = ['poten_time_11_mean', 'poten_time_11_min', 'poten_time_11_max']\n",
    "poten_feature_time_9 = ['poten_time_9_mean', 'poten_time_9_min', 'poten_time_9_max']\n",
    "\n",
    "poten_feature_3 = ['poten_neigh_3_mean', 'poten_neigh_3_min', 'poten_neigh_3_max']\n",
    "poten_feature_7 = ['poten_neigh_7_mean', 'poten_neigh_7_min', 'poten_neigh_7_max']\n",
    "poten_feature_9 = ['poten_neigh_9_mean', 'poten_neigh_9_min', 'poten_neigh_9_max']\n",
    "poten_feature_11 = ['poten_neigh_11_mean', 'poten_neigh_11_min', 'poten_neigh_11_max']\n",
    "poten_feature_13 = ['poten_neigh_13_mean', 'poten_neigh_13_min', 'poten_neigh_13_max']\n",
    "\n",
    "\n",
    "\n",
    "rhum_feature_5 = ['rhum_neigh_5_mean', 'rhum_neigh_5_min', 'rhum_neigh_5_max']\n",
    "rhum_feature_5_diag_pos = ['rhum_neigh_5_diag_pos_mean', 'rhum_neigh_5_diag_pos_min', 'rhum_neigh_5_diag_pos_max']\n",
    "rhum_feature_5_diag_neg1 = ['rhum_neigh_5_diag_neg1_mean', 'rhum_neigh_5_diag_neg1_min', 'rhum_neigh_5_diag_neg1_max']\n",
    "\n",
    "rhum_feature_5_lat = ['rhum_neigh_5_lat_mean', 'rhum_neigh_5_lat_min', 'rhum_neigh_5_lat_max']\n",
    "rhum_feature_5_lat_neg = ['rhum_neigh_5_lat_neg_mean', 'rhum_neigh_5_lat_neg_min', 'rhum_neigh_5_lat_neg_max']\n",
    "rhum_feature_5_lon_neg = ['rhum_neigh_5_lon_neg_mean', 'rhum_neigh_5_lon_neg_min', 'rhum_neigh_5_lon_neg_max']\n",
    "rhum_feature_5_lat_pos = ['rhum_neigh_5_lat_pos_mean', 'rhum_neigh_5_lat_pos_min', 'rhum_neigh_5_lat_pos_max']\n",
    "rhum_feature_5_lon_pos = ['rhum_neigh_5_lon_pos_mean', 'rhum_neigh_5_lon_pos_min', 'rhum_neigh_5_lon_pos_max']\n",
    "rhum_feature_5_lon = ['rhum_neigh_5_lon_mean', 'rhum_neigh_5_lon_min', 'rhum_neigh_5_lon_max']\n",
    "rhum_feature_9_lon = ['rhum_neigh_9_lon_mean', 'rhum_neigh_9_lon_min', 'rhum_neigh_9_lon_max']\n",
    "rhum_feature_11_lon = ['rhum_neigh_11_lon_mean', 'rhum_neigh_11_lon_min', 'rhum_neigh_11_lon_max']\n",
    "rhum_feature_15_lon = ['rhum_neigh_15_lon_mean', 'rhum_neigh_15_lon_min', 'rhum_neigh_15_lon_max']\n",
    "rhum_feature_11_lat = ['rhum_neigh_11_lat_mean', 'rhum_neigh_11_lat_min', 'rhum_neigh_11_lat_max']\n",
    "rhum_feature_9_lat = ['rhum_neigh_9_lat_mean', 'rhum_neigh_9_lat_min', 'rhum_neigh_9_lat_max']\n",
    "rhum_feature_time_3 = ['rhum_time_3_mean', 'rhum_time_3_min', 'rhum_time_3_max']\n",
    "rhum_feature_time_5 = ['rhum_time_5_mean', 'rhum_time_5_min', 'rhum_time_5_max']\n",
    "rhum_feature_time_5_pos = ['rhum_time_5_pos_mean', 'rhum_time_5_pos_min', 'rhum_time_5_pos_max']\n",
    "rhum_feature_time_7 = ['rhum_time_7_mean', 'rhum_time_7_min', 'rhum_time_7_max']\n",
    "rhum_feature_time_11 = ['rhum_time_11_mean', 'rhum_time_11_min', 'rhum_time_11_max']\n",
    "rhum_feature_time_7_mid = ['rhum_time_7_mid_mean', 'rhum_time_7_mid_min', 'rhum_time_7_mid_max']\n",
    "rhum_feature_time_14 = ['rhum_time_14_mean', 'rhum_time_14_min', 'rhum_time_14_max']\n",
    "rhum_feature_time_21 = ['rhum_time_21_mean', 'rhum_time_21_min', 'rhum_time_21_max']\n",
    "rhum_feature_time_28 = ['rhum_time_28_mean', 'rhum_time_28_min', 'rhum_time_28_max']\n",
    "rhum_feature_time_9 = ['rhum_time_9_mean', 'rhum_time_9_min', 'rhum_time_9_max']\n",
    "\n",
    "rhum_feature_3 = ['rhum_neigh_3_mean', 'rhum_neigh_3_min', 'rhum_neigh_3_max']\n",
    "rhum_feature_7 = ['rhum_neigh_7_mean', 'rhum_neigh_7_min', 'rhum_neigh_7_max']\n",
    "rhum_feature_9 = ['rhum_neigh_9_mean', 'rhum_neigh_9_min', 'rhum_neigh_9_max']\n",
    "rhum_feature_11 = ['rhum_neigh_11_mean', 'rhum_neigh_11_min', 'rhum_neigh_11_max']\n",
    "rhum_feature_13 = ['rhum_neigh_13_mean', 'rhum_neigh_13_min', 'rhum_neigh_13_max']\n",
    "\n",
    "\n",
    "slp_feature_5 = ['slp_neigh_5_mean', 'slp_neigh_5_min', 'slp_neigh_5_max']\n",
    "slp_feature_5_diag_pos = ['slp_neigh_5_diag_pos_mean', 'slp_neigh_5_diag_pos_min', 'slp_neigh_5_diag_pos_max']\n",
    "slp_feature_5_diag_neg1 = ['slp_neigh_5_diag_neg1_mean', 'slp_neigh_5_diag_neg1_min', 'slp_neigh_5_diag_neg1_max']\n",
    "slp_feature_5_lat = ['slp_neigh_5_lat_mean', 'slp_neigh_5_lat_min', 'slp_neigh_5_lat_max']\n",
    "slp_feature_5_lat_pos = ['slp_neigh_5_lat_pos_mean', 'slp_neigh_5_lat_pos_min', 'slp_neigh_5_lat_pos_max']\n",
    "slp_feature_5_lat_neg = ['slp_neigh_5_lat_neg_mean', 'slp_neigh_5_lat_neg_min', 'slp_neigh_5_lat_neg_max']\n",
    "slp_feature_5_lon_pos = ['slp_neigh_5_lon_pos_mean', 'slp_neigh_5_lon_pos_min', 'slp_neigh_5_lon_pos_max']\n",
    "slp_feature_5_lon_neg = ['slp_neigh_5_lon_neg_mean', 'slp_neigh_5_lon_neg_min', 'slp_neigh_5_lon_neg_max']\n",
    "slp_feature_5_lon = ['slp_neigh_5_lon_mean', 'slp_neigh_5_lon_min', 'slp_neigh_5_lon_max']\n",
    "slp_feature_9_lon = ['slp_neigh_9_lon_mean', 'slp_neigh_9_lon_min', 'slp_neigh_9_lon_max']\n",
    "slp_feature_11_lon = ['slp_neigh_11_lon_mean', 'slp_neigh_11_lon_min', 'slp_neigh_11_lon_max']\n",
    "slp_feature_15_lon = ['slp_neigh_15_lon_mean', 'slp_neigh_15_lon_min', 'slp_neigh_15_lon_max']\n",
    "slp_feature_11_lat = ['slp_neigh_11_lat_mean', 'slp_neigh_11_lat_min', 'slp_neigh_11_lat_max']\n",
    "slp_feature_9_lat = ['slp_neigh_9_lat_mean', 'slp_neigh_9_lat_min', 'slp_neigh_9_lat_max']\n",
    "slp_feature_time_5 = ['slp_time_5_mean', 'slp_time_5_min', 'slp_time_5_max']\n",
    "slp_feature_time_5_pos = ['slp_time_5_pos_mean', 'slp_time_5_pos_min', 'slp_time_5_pos_max']\n",
    "slp_feature_time_7 = ['slp_time_7_mean', 'slp_time_7_min', 'slp_time_7_max']\n",
    "slp_feature_time_11 = ['slp_time_11_mean', 'slp_time_11_min', 'slp_time_11_max']\n",
    "slp_feature_time_14 = ['slp_time_14_mean', 'slp_time_14_min', 'slp_time_14_max']\n",
    "slp_feature_time_9 = ['slp_time_9_mean', 'slp_time_9_min', 'slp_time_9_max']\n",
    "\n",
    "slp_feature_3 = ['slp_neigh_3_mean', 'slp_neigh_3_min', 'slp_neigh_3_max']\n",
    "slp_feature_7 = ['slp_neigh_7_mean', 'slp_neigh_7_min', 'slp_neigh_7_max']\n",
    "slp_feature_9 = ['slp_neigh_9_mean', 'slp_neigh_9_min', 'slp_neigh_9_max']\n",
    "slp_feature_11 = ['slp_neigh_11_mean', 'slp_neigh_11_min', 'slp_neigh_11_max']\n",
    "slp_feature_13 = ['slp_neigh_13_mean', 'slp_neigh_13_min', 'slp_neigh_13_max']\n",
    "\n",
    "\n",
    "precip_feature_5 = ['precip_neigh_5_mean', 'precip_neigh_5_min', 'precip_neigh_5_max']\n",
    "precip_feature_5_diag_pos = ['precip_neigh_5_diag_pos_mean', 'precip_neigh_5_diag_pos_min', 'precip_neigh_5_diag_pos_max']\n",
    "precip_feature_5_diag_neg1 = ['precip_neigh_5_diag_neg1_mean', 'precip_neigh_5_diag_neg1_min', 'precip_neigh_5_diag_neg1_max']\n",
    "precip_feature_5_lat = ['precip_neigh_5_lat_mean', 'precip_neigh_5_lat_min', 'precip_neigh_5_lat_max']\n",
    "precip_feature_5_lat_neg = ['precip_neigh_5_lat_neg_mean', 'precip_neigh_5_lat_neg_min', 'precip_neigh_5_lat_neg_max']\n",
    "precip_feature_5_lat_pos = ['precip_neigh_5_lat_pos_mean', 'precip_neigh_5_lat_pos_min', 'precip_neigh_5_lat_pos_max']\n",
    "precip_feature_5_lon_pos = ['precip_neigh_5_lon_pos_mean', 'precip_neigh_5_lon_pos_min', 'precip_neigh_5_lon_pos_max']\n",
    "precip_feature_5_lon_neg = ['precip_neigh_5_lon_neg_mean', 'precip_neigh_5_lon_neg_min', 'precip_neigh_5_lon_neg_max']\n",
    "precip_feature_5_lat = ['precip_neigh_5_lat_mean', 'precip_neigh_5_lat_min', 'precip_neigh_5_lat_max']\n",
    "precip_feature_5_lon = ['precip_neigh_5_lon_mean', 'precip_neigh_5_lon_min', 'precip_neigh_5_lon_max']\n",
    "precip_feature_9_lon = ['precip_neigh_9_lon_mean', 'precip_neigh_9_lon_min', 'precip_neigh_9_lon_max']\n",
    "precip_feature_11_lon = ['precip_neigh_11_lon_mean', 'precip_neigh_11_lon_min', 'precip_neigh_11_lon_max']\n",
    "precip_feature_15_lon = ['precip_neigh_15_lon_mean', 'precip_neigh_15_lon_min', 'precip_neigh_15_lon_max']\n",
    "precip_feature_11_lat = ['precip_neigh_11_lat_mean', 'precip_neigh_11_lat_min', 'precip_neigh_11_lat_max']\n",
    "precip_feature_9_lat = ['precip_neigh_9_lat_mean', 'precip_neigh_9_lat_min', 'precip_neigh_9_lat_max']\n",
    "precip_feature_time_3 = ['precip_time_3_mean', 'precip_time_3_min', 'precip_time_3_max']\n",
    "precip_feature_time_5 = ['precip_time_5_mean', 'precip_time_5_min', 'precip_time_5_max']\n",
    "precip_feature_time_5_pos = ['precip_time_5_pos_mean', 'precip_time_5_pos_min', 'precip_time_5_pos_max']\n",
    "precip_feature_time_7 = ['precip_time_7_mean', 'precip_time_7_min', 'precip_time_7_max']\n",
    "precip_feature_time_11 = ['precip_time_11_mean', 'precip_time_11_min', 'precip_time_11_max']\n",
    "precip_feature_time_7_mid = ['precip_time_7_mid_mean', 'precip_time_7_mid_min', 'precip_time_7_mid_max']\n",
    "precip_feature_time_9 = ['precip_time_9_mean', 'precip_time_9_min', 'precip_time_9_max']\n",
    "precip_feature_time_14 = ['precip_time_14_mean', 'precip_time_14_min', 'precip_time_14_max']\n",
    "precip_feature_time_21 = ['precip_time_21_mean', 'precip_time_21_min', 'precip_time_21_max']\n",
    "precip_feature_time_28 = ['precip_time_28_mean', 'precip_time_28_min', 'precip_time_28_max']\n",
    "\n",
    "precip_feature_3 = ['precip_neigh_3_mean', 'precip_neigh_3_min', 'precip_neigh_3_max']\n",
    "precip_feature_7 = ['precip_neigh_7_mean', 'precip_neigh_7_min', 'precip_neigh_7_max']\n",
    "precip_feature_9 = ['precip_neigh_9_mean', 'precip_neigh_9_min', 'precip_neigh_9_max']\n",
    "precip_feature_11 = ['precip_neigh_11_mean', 'precip_neigh_11_min', 'precip_neigh_11_max']\n",
    "precip_feature_13 = ['precip_neigh_13_mean', 'precip_neigh_13_min', 'precip_neigh_13_max']\n",
    "\n",
    "\n",
    "pres_feature_5 = ['pres_neigh_5_mean', 'pres_neigh_5_min', 'pres_neigh_5_max']\n",
    "pres_feature_5_diag_pos = ['pres_neigh_5_diag_pos_mean', 'pres_neigh_5_diag_pos_min', 'pres_neigh_5_diag_pos_max']\n",
    "pres_feature_5_diag_neg1 = ['pres_neigh_5_diag_neg1_mean', 'pres_neigh_5_diag_neg1_min', 'pres_neigh_5_diag_neg1_max']\n",
    "pres_feature_5_lat = ['pres_neigh_5_lat_mean', 'pres_neigh_5_lat_min', 'pres_neigh_5_lat_max']\n",
    "pres_feature_5_lat_neg = ['pres_neigh_5_lat_neg_mean', 'pres_neigh_5_lat_neg_min', 'pres_neigh_5_lat_neg_max']\n",
    "pres_feature_5_lon_neg = ['pres_neigh_5_lon_neg_mean', 'pres_neigh_5_lon_neg_min', 'pres_neigh_5_lon_neg_max']\n",
    "pres_feature_5_lat_pos = ['pres_neigh_5_lat_pos_mean', 'pres_neigh_5_lat_pos_min', 'pres_neigh_5_lat_pos_max']\n",
    "pres_feature_5_lon_pos = ['pres_neigh_5_lon_pos_mean', 'pres_neigh_5_lon_pos_min', 'pres_neigh_5_lon_pos_max']\n",
    "pres_feature_5_lon = ['pres_neigh_5_lon_mean', 'pres_neigh_5_lon_min', 'pres_neigh_5_lon_max']\n",
    "pres_feature_9_lon = ['pres_neigh_9_lon_mean', 'pres_neigh_9_lon_min', 'pres_neigh_9_lon_max']\n",
    "pres_feature_15_lon = ['pres_neigh_15_lon_mean', 'pres_neigh_15_lon_min', 'pres_neigh_15_lon_max']\n",
    "pres_feature_11_lat = ['pres_neigh_11_lat_mean', 'pres_neigh_11_lat_min', 'pres_neigh_11_lat_max']\n",
    "pres_feature_9_lat = ['pres_neigh_9_lat_mean', 'pres_neigh_9_lat_min', 'pres_neigh_9_lat_max']\n",
    "pres_feature_time_3 = ['pres_time_3_mean', 'pres_time_3_min', 'pres_time_3_max']\n",
    "pres_feature_time_5 = ['pres_time_5_mean', 'pres_time_5_min', 'pres_time_5_max']\n",
    "pres_feature_time_5_pos = ['pres_time_5_pos_mean', 'pres_time_5_pos_min', 'pres_time_5_pos_max']\n",
    "pres_feature_time_7 = ['pres_time_7_mean', 'pres_time_7_min', 'pres_time_7_max']\n",
    "pres_feature_time_11 = ['pres_time_11_mean', 'pres_time_11_min', 'pres_time_11_max']\n",
    "pres_feature_time_7_mid = ['pres_time_7_mid_mean', 'pres_time_7_mid_min', 'pres_time_7_mid_max']\n",
    "pres_feature_time_9 = ['pres_time_9_mean', 'pres_time_9_min', 'pres_time_9_max']\n",
    "pres_feature_time_14 = ['pres_time_14_mean', 'pres_time_14_min', 'pres_time_14_max']\n",
    "pres_feature_time_21 = ['pres_time_21_mean', 'pres_time_21_min', 'pres_time_21_max']\n",
    "pres_feature_time_28 = ['pres_time_28_mean', 'pres_time_28_min', 'pres_time_28_max']\n",
    "\n",
    "pres_feature_3 = ['pres_neigh_3_mean', 'pres_neigh_3_min', 'pres_neigh_3_max']\n",
    "pres_feature_7 = ['pres_neigh_7_mean', 'pres_neigh_7_min', 'pres_neigh_7_max']\n",
    "pres_feature_9 = ['pres_neigh_9_mean', 'pres_neigh_9_min', 'pres_neigh_9_max']\n",
    "pres_feature_11 = ['pres_neigh_11_mean', 'pres_neigh_11_min', 'pres_neigh_11_max']\n",
    "pres_feature_13 = ['pres_neigh_13_mean', 'pres_neigh_13_min', 'pres_neigh_13_max']\n",
    "\n",
    "\n",
    "\n",
    "wind_feature_11 = ['wind_500_neigh_11_mean', 'wind_500_neigh_11_min', 'wind_500_neigh_11_max']\n",
    "wind_feature_9 = ['wind_500_neigh_9_mean', 'wind_500_neigh_9_min', 'wind_500_neigh_9_max']\n",
    "wind_feature_5 = ['wind_500_neigh_5_mean', 'wind_500_neigh_5_min', 'wind_500_neigh_5_max']\n",
    "wind_feature_5_diag_pos = ['wind_500_neigh_5_diag_pos_mean', 'wind_500_neigh_5_diag_pos_min', 'wind_500_neigh_5_diag_pos_max']\n",
    "wind_feature_5_diag_neg1 = ['wind_500_neigh_5_diag_neg1_mean', 'wind_500_neigh_5_diag_neg1_min', 'wind_500_neigh_5_diag_neg1_max']\n",
    "wind_feature_5_lat = ['wind_500_neigh_5_lat_mean', 'wind_500_neigh_5_lat_min', 'wind_500_neigh_5_lat_max']\n",
    "wind_feature_5_lat_pos = ['wind_500_neigh_5_lat_pos_mean', 'wind_500_neigh_5_lat_pos_min', 'wind_500_neigh_5_lat_pos_max']\n",
    "wind_feature_5_lat_neg = ['wind_500_neigh_5_lat_neg_mean', 'wind_500_neigh_5_lat_neg_min', 'wind_500_neigh_5_lat_neg_max']\n",
    "wind_feature_5_lon_pos = ['wind_500_neigh_5_lon_pos_mean', 'wind_500_neigh_5_lon_pos_min', 'wind_500_neigh_5_lon_pos_max']\n",
    "wind_feature_5_lon_neg = ['wind_500_neigh_5_lon_neg_mean', 'wind_500_neigh_5_lon_neg_min', 'wind_500_neigh_5_lon_neg_max']\n",
    "wind_feature_5_lon = ['wind_500_neigh_5_lon_mean', 'wind_500_neigh_5_lon_min', 'wind_500_neigh_5_lon_max']\n",
    "wind_feature_9_lon = ['wind_500_neigh_9_lon_mean', 'wind_500_neigh_9_lon_min', 'wind_500_neigh_9_lon_max']\n",
    "wind_feature_11_lon = ['wind_500_neigh_11_lon_mean', 'wind_500_neigh_11_lon_min', 'wind_500_neigh_11_lon_max']\n",
    "wind_feature_15_lon = ['wind_500_neigh_15_lon_mean', 'wind_500_neigh_15_lon_min', 'wind_500_neigh_15_lon_max']\n",
    "wind_feature_11_lat = ['wind_500_neigh_11_lat_mean', 'wind_500_neigh_11_lat_min', 'wind_500_neigh_11_lat_max']\n",
    "wind_feature_9_lat = ['wind_500_neigh_9_lat_mean', 'wind_500_neigh_9_lat_min', 'wind_500_neigh_9_lat_max']\n",
    "wind_feature_time_5 = ['wind_500_time_5_mean', 'wind_500_time_5_min', 'wind_500_time_5_max']\n",
    "wind_feature_time_5_pos = ['wind_500_time_5_pos_mean', 'wind_500_time_5_pos_min', 'wind_500_time_5_pos_max']\n",
    "wind_feature_time_7 = ['wind_500_time_7_mean', 'wind_500_time_7_min', 'wind_500_time_7_max']\n",
    "wind_feature_time_14 = ['wind_500_time_14_mean', 'wind_500_time_14_min', 'wind_500_time_14_max']\n",
    "wind_feature_time_9 = ['wind_500_time_9_mean', 'wind_500_time_9_min', 'wind_500_time_9_max']\n",
    "wind_feature_time_11 = ['wind_500_time_11_mean', 'wind_500_time_11_min', 'wind_500_time_11_max']\n",
    "wind_feature_7 = ['wind_500_neigh_7_mean', 'wind_500_neigh_7_min', 'wind_500_neigh_7_max']\n",
    "wind_feature_3 = ['wind_500_neigh_3_mean', 'wind_500_neigh_3_min', 'wind_500_neigh_3_max']\n",
    "wind_feature_13 = ['wind_500_neigh_13_mean', 'wind_500_neigh_13_min', 'wind_500_neigh_13_max']\n",
    "\n",
    "sst_features_time_5 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_time_5 = sst_features_time_5 + [f'sst_{i}_time_5_mean', f'sst_{i}_time_5_min', f'sst_{i}_time_5_max']\n",
    "\n",
    "sst_features_time_7 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_time_7 = sst_features_time_7 + [f'sst_{i}_time_7_mean', f'sst_{i}_time_7_min', f'sst_{i}_time_7_max']\n",
    "\n",
    "\n",
    "sst_features_time_14 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_time_14 = sst_features_time_14 + [f'sst_{i}_time_14_mean', f'sst_{i}_time_14_min', f'sst_{i}_time_14_max']\n",
    "\n",
    "sst_features_time_9 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_time_9 = sst_features_time_9 + [f'sst_{i}_time_9_mean', f'sst_{i}_time_9_min', f'sst_{i}_time_9_max']\n",
    "\n",
    "\n",
    "sst_features_time_11 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_time_11 = sst_features_time_11 + [f'sst_{i}_time_11_mean', f'sst_{i}_time_11_min', f'sst_{i}_time_11_max']\n",
    "\n",
    "sst_features_11 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_11 = sst_features_11 + [f'sst_{i}_neigh_11_mean', f'sst_{i}_neigh_11_min', f'sst_{i}_neigh_11_max']\n",
    "\n",
    "sst_features_3 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_3 = sst_features_3 + [f'sst_{i}_neigh_3_mean', f'sst_{i}_neigh_3_min', f'sst_{i}_neigh_3_max']\n",
    "\n",
    "sst_features_7 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_7 = sst_features_7 + [f'sst_{i}_neigh_7_mean', f'sst_{i}_neigh_7_min', f'sst_{i}_neigh_7_max']\n",
    "\n",
    "sst_features_5_lat = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_5_lat = sst_features_5_lat + [f'sst_{i}_neigh_5_lat_mean', f'sst_{i}_neigh_5_lat_min', f'sst_{i}_neigh_5_lat_max']\n",
    "\n",
    "sst_features_5_lon = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_5_lon = sst_features_5_lon + [f'sst_{i}_neigh_5_lon_mean', f'sst_{i}_neigh_5_lon_min', f'sst_{i}_neigh_5_lon_max']\n",
    "\n",
    "sst_features_9_lon = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_9_lon = sst_features_9_lon + [f'sst_{i}_neigh_9_lon_mean', f'sst_{i}_neigh_9_lon_min', f'sst_{i}_neigh_9_lon_max']\n",
    "\n",
    "sst_features_11_lon = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_11_lon = sst_features_11_lon + [f'sst_{i}_neigh_11_lon_mean', f'sst_{i}_neigh_11_lon_min', f'sst_{i}_neigh_11_lon_max']\n",
    "\n",
    "sst_features_15_lon = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_15_lon = sst_features_15_lon + [f'sst_{i}_neigh_15_lon_mean', f'sst_{i}_neigh_15_lon_min', f'sst_{i}_neigh_15_lon_max']\n",
    "\n",
    "sst_features_11_lat = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_11_lat = sst_features_11_lat + [f'sst_{i}_neigh_11_lat_mean', f'sst_{i}_neigh_11_lat_min', f'sst_{i}_neigh_11_lat_max']\n",
    "\n",
    "sst_features_9_lat = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_9_lat = sst_features_9_lat + [f'sst_{i}_neigh_9_lat_mean', f'sst_{i}_neigh_9_lat_min', f'sst_{i}_neigh_9_lat_max']\n",
    "    \n",
    "sst_features_9 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_9 = sst_features_9 + [f'sst_{i}_neigh_9_mean', f'sst_{i}_neigh_9_min', f'sst_{i}_neigh_9_max']\n",
    "\n",
    "sst_features_13 = []\n",
    "for i in [1, 5, 3, 4]:\n",
    "    sst_features_13 = sst_features_13 + [f'sst_{i}_neigh_13_mean', f'sst_{i}_neigh_13_min', f'sst_{i}_neigh_13_max']\n",
    "\n",
    "\n",
    "poten_feature_5 = ['poten_neigh_5_mean', 'poten_neigh_5_min', 'poten_neigh_5_max']\n",
    "poten_feature_time_5 = ['poten_time_5_mean', 'poten_time_5_min', 'poten_time_5_max']\n",
    "poten_feature_time_7 = ['poten_time_7_mean', 'poten_time_7_min', 'poten_time_7_max']\n",
    "poten_feature_time_11 = ['poten_time_11_mean', 'poten_time_11_min', 'poten_time_11_max']\n",
    "poten_feature_time_9 = ['poten_time_9_mean', 'poten_time_9_min', 'poten_time_9_max']\n",
    "\n",
    "poten_feature_3 = ['poten_neigh_3_mean', 'poten_neigh_3_min', 'poten_neigh_3_max']\n",
    "poten_feature_7 = ['poten_neigh_7_mean', 'poten_neigh_7_min', 'poten_neigh_7_max']\n",
    "poten_feature_9 = ['poten_neigh_9_mean', 'poten_neigh_9_min', 'poten_neigh_9_max']\n",
    "poten_feature_11 = ['poten_neigh_11_mean', 'poten_neigh_11_min', 'poten_neigh_11_max']\n",
    "poten_feature_13 = ['poten_neigh_13_mean', 'poten_neigh_13_min', 'poten_neigh_13_max']\n",
    "\n",
    "\n",
    "\n",
    "rhum_feature_5 = ['rhum_neigh_5_mean', 'rhum_neigh_5_min', 'rhum_neigh_5_max']\n",
    "rhum_feature_5_diag_11 = ['rhum_neigh_5_diag_11_mean', 'rhum_neigh_5_diag_11_min', 'rhum_neigh_5_diag_11_max']\n",
    "rhum_feature_5_diag_10 = ['rhum_neigh_5_diag_10_mean', 'rhum_neigh_5_diag_10_min', 'rhum_neigh_5_diag_10_max']\n",
    "rhum_feature_5_diag_01 = ['rhum_neigh_5_diag_01_mean', 'rhum_neigh_5_diag_01_min', 'rhum_neigh_5_diag_01_max']\n",
    "rhum_feature_5_diag_00 = ['rhum_neigh_5_diag_00_mean', 'rhum_neigh_5_diag_00_min', 'rhum_neigh_5_diag_00_max']\n",
    "rhum_feature_5_diag_pos = ['rhum_neigh_5_diag_pos_mean', 'rhum_neigh_5_diag_pos_min', 'rhum_neigh_5_diag_pos_max']\n",
    "\n",
    "rhum_feature_5_lat = ['rhum_neigh_5_lat_mean', 'rhum_neigh_5_lat_min', 'rhum_neigh_5_lat_max']\n",
    "rhum_feature_5_lon = ['rhum_neigh_5_lon_mean', 'rhum_neigh_5_lon_min', 'rhum_neigh_5_lon_max']\n",
    "rhum_feature_9_lon = ['rhum_neigh_9_lon_mean', 'rhum_neigh_9_lon_min', 'rhum_neigh_9_lon_max']\n",
    "rhum_feature_11_lon = ['rhum_neigh_11_lon_mean', 'rhum_neigh_11_lon_min', 'rhum_neigh_11_lon_max']\n",
    "rhum_feature_15_lon = ['rhum_neigh_15_lon_mean', 'rhum_neigh_15_lon_min', 'rhum_neigh_15_lon_max']\n",
    "rhum_feature_11_lat = ['rhum_neigh_11_lat_mean', 'rhum_neigh_11_lat_min', 'rhum_neigh_11_lat_max']\n",
    "rhum_feature_9_lat = ['rhum_neigh_9_lat_mean', 'rhum_neigh_9_lat_min', 'rhum_neigh_9_lat_max']\n",
    "rhum_feature_time_3 = ['rhum_time_3_mean', 'rhum_time_3_min', 'rhum_time_3_max']\n",
    "rhum_feature_time_5 = ['rhum_time_5_mean', 'rhum_time_5_min', 'rhum_time_5_max']\n",
    "rhum_feature_time_7 = ['rhum_time_7_mean', 'rhum_time_7_min', 'rhum_time_7_max']\n",
    "rhum_feature_time_11 = ['rhum_time_11_mean', 'rhum_time_11_min', 'rhum_time_11_max']\n",
    "rhum_feature_time_7_mid = ['rhum_time_7_mid_mean', 'rhum_time_7_mid_min', 'rhum_time_7_mid_max']\n",
    "rhum_feature_time_14 = ['rhum_time_14_mean', 'rhum_time_14_min', 'rhum_time_14_max']\n",
    "rhum_feature_time_21 = ['rhum_time_21_mean', 'rhum_time_21_min', 'rhum_time_21_max']\n",
    "rhum_feature_time_28 = ['rhum_time_28_mean', 'rhum_time_28_min', 'rhum_time_28_max']\n",
    "rhum_feature_time_9 = ['rhum_time_9_mean', 'rhum_time_9_min', 'rhum_time_9_max']\n",
    "\n",
    "rhum_feature_3 = ['rhum_neigh_3_mean', 'rhum_neigh_3_min', 'rhum_neigh_3_max']\n",
    "rhum_feature_7 = ['rhum_neigh_7_mean', 'rhum_neigh_7_min', 'rhum_neigh_7_max']\n",
    "rhum_feature_9 = ['rhum_neigh_9_mean', 'rhum_neigh_9_min', 'rhum_neigh_9_max']\n",
    "rhum_feature_11 = ['rhum_neigh_11_mean', 'rhum_neigh_11_min', 'rhum_neigh_11_max']\n",
    "rhum_feature_13 = ['rhum_neigh_13_mean', 'rhum_neigh_13_min', 'rhum_neigh_13_max']\n",
    "\n",
    "\n",
    "slp_feature_5 = ['slp_neigh_5_mean', 'slp_neigh_5_min', 'slp_neigh_5_max']\n",
    "slp_feature_5_diag_11 = ['slp_neigh_5_diag_11_mean', 'slp_neigh_5_diag_11_min', 'slp_neigh_5_diag_11_max']\n",
    "slp_feature_5_diag_10 = ['slp_neigh_5_diag_10_mean', 'slp_neigh_5_diag_10_min', 'slp_neigh_5_diag_10_max']\n",
    "slp_feature_5_diag_01 = ['slp_neigh_5_diag_01_mean', 'slp_neigh_5_diag_01_min', 'slp_neigh_5_diag_01_max']\n",
    "slp_feature_5_diag_00 = ['slp_neigh_5_diag_00_mean', 'slp_neigh_5_diag_00_min', 'slp_neigh_5_diag_00_max']\n",
    "slp_feature_5_diag_pos = ['slp_neigh_5_diag_pos_mean', 'slp_neigh_5_diag_pos_min', 'slp_neigh_5_diag_pos_max']\n",
    "slp_feature_5_lat = ['slp_neigh_5_lat_mean', 'slp_neigh_5_lat_min', 'slp_neigh_5_lat_max']\n",
    "slp_feature_5_lon = ['slp_neigh_5_lon_mean', 'slp_neigh_5_lon_min', 'slp_neigh_5_lon_max']\n",
    "slp_feature_9_lon = ['slp_neigh_9_lon_mean', 'slp_neigh_9_lon_min', 'slp_neigh_9_lon_max']\n",
    "slp_feature_11_lon = ['slp_neigh_11_lon_mean', 'slp_neigh_11_lon_min', 'slp_neigh_11_lon_max']\n",
    "slp_feature_15_lon = ['slp_neigh_15_lon_mean', 'slp_neigh_15_lon_min', 'slp_neigh_15_lon_max']\n",
    "slp_feature_11_lat = ['slp_neigh_11_lat_mean', 'slp_neigh_11_lat_min', 'slp_neigh_11_lat_max']\n",
    "slp_feature_9_lat = ['slp_neigh_9_lat_mean', 'slp_neigh_9_lat_min', 'slp_neigh_9_lat_max']\n",
    "slp_feature_time_5 = ['slp_time_5_mean', 'slp_time_5_min', 'slp_time_5_max']\n",
    "slp_feature_time_7 = ['slp_time_7_mean', 'slp_time_7_min', 'slp_time_7_max']\n",
    "slp_feature_time_11 = ['slp_time_11_mean', 'slp_time_11_min', 'slp_time_11_max']\n",
    "slp_feature_time_14 = ['slp_time_14_mean', 'slp_time_14_min', 'slp_time_14_max']\n",
    "slp_feature_time_9 = ['slp_time_9_mean', 'slp_time_9_min', 'slp_time_9_max']\n",
    "\n",
    "slp_feature_3 = ['slp_neigh_3_mean', 'slp_neigh_3_min', 'slp_neigh_3_max']\n",
    "slp_feature_7 = ['slp_neigh_7_mean', 'slp_neigh_7_min', 'slp_neigh_7_max']\n",
    "slp_feature_9 = ['slp_neigh_9_mean', 'slp_neigh_9_min', 'slp_neigh_9_max']\n",
    "slp_feature_11 = ['slp_neigh_11_mean', 'slp_neigh_11_min', 'slp_neigh_11_max']\n",
    "slp_feature_13 = ['slp_neigh_13_mean', 'slp_neigh_13_min', 'slp_neigh_13_max']\n",
    "\n",
    "\n",
    "precip_feature_5 = ['precip_neigh_5_mean', 'precip_neigh_5_min', 'precip_neigh_5_max']\n",
    "precip_feature_5_diag_11 = ['precip_neigh_5_diag_11_mean', 'precip_neigh_5_diag_11_min', 'precip_neigh_5_diag_11_max']\n",
    "precip_feature_5_diag_10 = ['precip_neigh_5_diag_10_mean', 'precip_neigh_5_diag_10_min', 'precip_neigh_5_diag_10_max']\n",
    "precip_feature_5_diag_01 = ['precip_neigh_5_diag_01_mean', 'precip_neigh_5_diag_01_min', 'precip_neigh_5_diag_01_max']\n",
    "precip_feature_5_diag_00 = ['precip_neigh_5_diag_00_mean', 'precip_neigh_5_diag_00_min', 'precip_neigh_5_diag_00_max']\n",
    "precip_feature_5_diag_pos = ['precip_neigh_5_diag_pos_mean', 'precip_neigh_5_diag_pos_min', 'precip_neigh_5_diag_pos_max']\n",
    "precip_feature_5_lat = ['precip_neigh_5_lat_mean', 'precip_neigh_5_lat_min', 'precip_neigh_5_lat_max']\n",
    "precip_feature_5_lon = ['precip_neigh_5_lon_mean', 'precip_neigh_5_lon_min', 'precip_neigh_5_lon_max']\n",
    "precip_feature_9_lon = ['precip_neigh_9_lon_mean', 'precip_neigh_9_lon_min', 'precip_neigh_9_lon_max']\n",
    "precip_feature_11_lon = ['precip_neigh_11_lon_mean', 'precip_neigh_11_lon_min', 'precip_neigh_11_lon_max']\n",
    "precip_feature_15_lon = ['precip_neigh_15_lon_mean', 'precip_neigh_15_lon_min', 'precip_neigh_15_lon_max']\n",
    "precip_feature_11_lat = ['precip_neigh_11_lat_mean', 'precip_neigh_11_lat_min', 'precip_neigh_11_lat_max']\n",
    "precip_feature_9_lat = ['precip_neigh_9_lat_mean', 'precip_neigh_9_lat_min', 'precip_neigh_9_lat_max']\n",
    "precip_feature_time_3 = ['precip_time_3_mean', 'precip_time_3_min', 'precip_time_3_max']\n",
    "precip_feature_time_5 = ['precip_time_5_mean', 'precip_time_5_min', 'precip_time_5_max']\n",
    "precip_feature_time_7 = ['precip_time_7_mean', 'precip_time_7_min', 'precip_time_7_max']\n",
    "precip_feature_time_11 = ['precip_time_11_mean', 'precip_time_11_min', 'precip_time_11_max']\n",
    "precip_feature_time_7_mid = ['precip_time_7_mid_mean', 'precip_time_7_mid_min', 'precip_time_7_mid_max']\n",
    "precip_feature_time_9 = ['precip_time_9_mean', 'precip_time_9_min', 'precip_time_9_max']\n",
    "precip_feature_time_14 = ['precip_time_14_mean', 'precip_time_14_min', 'precip_time_14_max']\n",
    "precip_feature_time_21 = ['precip_time_21_mean', 'precip_time_21_min', 'precip_time_21_max']\n",
    "precip_feature_time_28 = ['precip_time_28_mean', 'precip_time_28_min', 'precip_time_28_max']\n",
    "\n",
    "precip_feature_3 = ['precip_neigh_3_mean', 'precip_neigh_3_min', 'precip_neigh_3_max']\n",
    "precip_feature_7 = ['precip_neigh_7_mean', 'precip_neigh_7_min', 'precip_neigh_7_max']\n",
    "precip_feature_9 = ['precip_neigh_9_mean', 'precip_neigh_9_min', 'precip_neigh_9_max']\n",
    "precip_feature_11 = ['precip_neigh_11_mean', 'precip_neigh_11_min', 'precip_neigh_11_max']\n",
    "precip_feature_13 = ['precip_neigh_13_mean', 'precip_neigh_13_min', 'precip_neigh_13_max']\n",
    "\n",
    "\n",
    "pres_feature_5 = ['pres_neigh_5_mean', 'pres_neigh_5_min', 'pres_neigh_5_max']\n",
    "pres_feature_5_diag_11 = ['pres_neigh_5_diag_11_mean', 'pres_neigh_5_diag_11_min', 'pres_neigh_5_diag_11_max']\n",
    "pres_feature_5_diag_10 = ['pres_neigh_5_diag_10_mean', 'pres_neigh_5_diag_10_min', 'pres_neigh_5_diag_10_max']\n",
    "pres_feature_5_diag_01 = ['pres_neigh_5_diag_01_mean', 'pres_neigh_5_diag_01_min', 'pres_neigh_5_diag_01_max']\n",
    "pres_feature_5_diag_00 = ['pres_neigh_5_diag_00_mean', 'pres_neigh_5_diag_00_min', 'pres_neigh_5_diag_00_max']\n",
    "pres_feature_5_diag_pos = ['pres_neigh_5_diag_pos_mean', 'pres_neigh_5_diag_pos_min', 'pres_neigh_5_diag_pos_max']\n",
    "pres_feature_5_lat = ['pres_neigh_5_lat_mean', 'pres_neigh_5_lat_min', 'pres_neigh_5_lat_max']\n",
    "pres_feature_5_lon = ['pres_neigh_5_lon_mean', 'pres_neigh_5_lon_min', 'pres_neigh_5_lon_max']\n",
    "pres_feature_9_lon = ['pres_neigh_9_lon_mean', 'pres_neigh_9_lon_min', 'pres_neigh_9_lon_max']\n",
    "pres_feature_15_lon = ['pres_neigh_15_lon_mean', 'pres_neigh_15_lon_min', 'pres_neigh_15_lon_max']\n",
    "pres_feature_11_lat = ['pres_neigh_11_lat_mean', 'pres_neigh_11_lat_min', 'pres_neigh_11_lat_max']\n",
    "pres_feature_9_lat = ['pres_neigh_9_lat_mean', 'pres_neigh_9_lat_min', 'pres_neigh_9_lat_max']\n",
    "pres_feature_time_3 = ['pres_time_3_mean', 'pres_time_3_min', 'pres_time_3_max']\n",
    "pres_feature_time_5 = ['pres_time_5_mean', 'pres_time_5_min', 'pres_time_5_max']\n",
    "pres_feature_time_7 = ['pres_time_7_mean', 'pres_time_7_min', 'pres_time_7_max']\n",
    "pres_feature_time_11 = ['pres_time_11_mean', 'pres_time_11_min', 'pres_time_11_max']\n",
    "pres_feature_time_7_mid = ['pres_time_7_mid_mean', 'pres_time_7_mid_min', 'pres_time_7_mid_max']\n",
    "pres_feature_time_9 = ['pres_time_9_mean', 'pres_time_9_min', 'pres_time_9_max']\n",
    "pres_feature_time_14 = ['pres_time_14_mean', 'pres_time_14_min', 'pres_time_14_max']\n",
    "pres_feature_time_21 = ['pres_time_21_mean', 'pres_time_21_min', 'pres_time_21_max']\n",
    "pres_feature_time_28 = ['pres_time_28_mean', 'pres_time_28_min', 'pres_time_28_max']\n",
    "\n",
    "pres_feature_3 = ['pres_neigh_3_mean', 'pres_neigh_3_min', 'pres_neigh_3_max']\n",
    "pres_feature_7 = ['pres_neigh_7_mean', 'pres_neigh_7_min', 'pres_neigh_7_max']\n",
    "pres_feature_9 = ['pres_neigh_9_mean', 'pres_neigh_9_min', 'pres_neigh_9_max']\n",
    "pres_feature_11 = ['pres_neigh_11_mean', 'pres_neigh_11_min', 'pres_neigh_11_max']\n",
    "pres_feature_13 = ['pres_neigh_13_mean', 'pres_neigh_13_min', 'pres_neigh_13_max']\n",
    "\n",
    "\n",
    "\n",
    "wind_feature_11 = ['wind_500_neigh_11_mean', 'wind_500_neigh_11_min', 'wind_500_neigh_11_max']\n",
    "wind_feature_9 = ['wind_500_neigh_9_mean', 'wind_500_neigh_9_min', 'wind_500_neigh_9_max']\n",
    "wind_feature_5 = ['wind_500_neigh_5_mean', 'wind_500_neigh_5_min', 'wind_500_neigh_5_max']\n",
    "wind_feature_5_diag_11 = ['wind_500_neigh_5_diag_11_mean', 'wind_500_neigh_5_diag_11_min', 'wind_500_neigh_5_diag_11_max']\n",
    "wind_feature_5_diag_10 = ['wind_500_neigh_5_diag_10_mean', 'wind_500_neigh_5_diag_10_min', 'wind_500_neigh_5_diag_10_max']\n",
    "wind_feature_5_diag_01 = ['wind_500_neigh_5_diag_01_mean', 'wind_500_neigh_5_diag_01_min', 'wind_500_neigh_5_diag_01_max']\n",
    "wind_feature_5_diag_00 = ['wind_500_neigh_5_diag_00_mean', 'wind_500_neigh_5_diag_00_min', 'wind_500_neigh_5_diag_00_max']\n",
    "wind_feature_5_diag_pos = ['wind_500_neigh_5_diag_pos_mean', 'wind_500_neigh_5_diag_pos_min', 'wind_500_neigh_5_diag_pos_max']\n",
    "wind_feature_5_lat = ['wind_500_neigh_5_lat_mean', 'wind_500_neigh_5_lat_min', 'wind_500_neigh_5_lat_max']\n",
    "wind_feature_5_lon = ['wind_500_neigh_5_lon_mean', 'wind_500_neigh_5_lon_min', 'wind_500_neigh_5_lon_max']\n",
    "wind_feature_9_lon = ['wind_500_neigh_9_lon_mean', 'wind_500_neigh_9_lon_min', 'wind_500_neigh_9_lon_max']\n",
    "wind_feature_11_lon = ['wind_500_neigh_11_lon_mean', 'wind_500_neigh_11_lon_min', 'wind_500_neigh_11_lon_max']\n",
    "wind_feature_15_lon = ['wind_500_neigh_15_lon_mean', 'wind_500_neigh_15_lon_min', 'wind_500_neigh_15_lon_max']\n",
    "wind_feature_11_lat = ['wind_500_neigh_11_lat_mean', 'wind_500_neigh_11_lat_min', 'wind_500_neigh_11_lat_max']\n",
    "wind_feature_9_lat = ['wind_500_neigh_9_lat_mean', 'wind_500_neigh_9_lat_min', 'wind_500_neigh_9_lat_max']\n",
    "wind_feature_time_5 = ['wind_500_time_5_mean', 'wind_500_time_5_min', 'wind_500_time_5_max']\n",
    "wind_feature_time_7 = ['wind_500_time_7_mean', 'wind_500_time_7_min', 'wind_500_time_7_max']\n",
    "wind_feature_time_14 = ['wind_500_time_14_mean', 'wind_500_time_14_min', 'wind_500_time_14_max']\n",
    "wind_feature_time_9 = ['wind_500_time_9_mean', 'wind_500_time_9_min', 'wind_500_time_9_max']\n",
    "wind_feature_time_11 = ['wind_500_time_11_mean', 'wind_500_time_11_min', 'wind_500_time_11_max']\n",
    "wind_feature_7 = ['wind_500_neigh_7_mean', 'wind_500_neigh_7_min', 'wind_500_neigh_7_max']\n",
    "wind_feature_3 = ['wind_500_neigh_3_mean', 'wind_500_neigh_3_min', 'wind_500_neigh_3_max']\n",
    "wind_feature_13 = ['wind_500_neigh_13_mean', 'wind_500_neigh_13_min', 'wind_500_neigh_13_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8c5195b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2233163/1759131708.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/1759131708.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/1759131708.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/1759131708.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/1759131708.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/1759131708.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/1759131708.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/1759131708.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/1759131708.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/1759131708.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/1759131708.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('df_fe_5_lon_neg_neigh.csv')\n",
    "df2 = pd.read_csv('df_fe_5_lon_pos_neigh.csv')\n",
    "df3 = pd.read_csv('df_fe_5_lat_pos_neigh.csv')\n",
    "df4 = pd.read_csv('df_fe_5_lat_neg_neigh.csv')\n",
    "cols4 = sst_features_5_lat_neg + wind_feature_5_lat_neg + slp_feature_5_lat_neg + precip_feature_5_lat_neg + pres_feature_5_lat_neg + rhum_feature_5_lat_neg\n",
    "df[cols4] = df4[cols4]\n",
    "\n",
    "cols1 = sst_features_5_lon_neg + wind_feature_5_lon_neg + slp_feature_5_lon_neg + precip_feature_5_lon_neg + pres_feature_5_lon_neg + rhum_feature_5_lon_neg\n",
    "df[cols1] = df1[cols1]\n",
    "\n",
    "cols2 = sst_features_5_lon_pos + wind_feature_5_lon_pos + slp_feature_5_lon_pos + precip_feature_5_lon_pos + pres_feature_5_lon_pos + rhum_feature_5_lon_pos \n",
    "df[cols2] = df2[cols2]\n",
    "\n",
    "cols3 = sst_features_5_lat_pos + wind_feature_5_lat_pos + slp_feature_5_lat_pos + precip_feature_5_lat_pos + pres_feature_5_lat_pos + rhum_feature_5_lat_pos\n",
    "df[cols3] = df3[cols3]\n",
    "\n",
    "del df1, df2, df3, df4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11bf55d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols4] = df4[cols4]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols1] = df1[cols1]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols2] = df2[cols2]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n",
      "/tmp/ipykernel_2233163/911554408.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[cols3] = df3[cols3]\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('df_fe_5_diag_11_neigh.csv')\n",
    "df2 = pd.read_csv('df_fe_5_diag_01_neigh.csv')\n",
    "df3 = pd.read_csv('df_fe_5_diag_10_neigh.csv')\n",
    "df4 = pd.read_csv('df_fe_5_diag_00_neigh.csv')\n",
    "cols4 = sst_features_5_diag_00 + wind_feature_5_diag_00 + slp_feature_5_diag_00 + precip_feature_5_diag_00 + pres_feature_5_diag_00 + rhum_feature_5_diag_00\n",
    "df[cols4] = df4[cols4]\n",
    "\n",
    "cols1 = sst_features_5_diag_11 + wind_feature_5_diag_11 + slp_feature_5_diag_11 + precip_feature_5_diag_11 + pres_feature_5_diag_11 + rhum_feature_5_diag_11\n",
    "df[cols1] = df1[cols1]\n",
    "\n",
    "cols2 = sst_features_5_diag_01 + wind_feature_5_diag_01 + slp_feature_5_diag_01 + precip_feature_5_diag_01 + pres_feature_5_diag_01 + rhum_feature_5_diag_01 \n",
    "df[cols2] = df2[cols2]\n",
    "\n",
    "cols3 = sst_features_5_diag_10 + wind_feature_5_diag_10 + slp_feature_5_diag_10 + precip_feature_5_diag_10 + pres_feature_5_diag_10 + rhum_feature_5_diag_10\n",
    "df[cols3] = df3[cols3]\n",
    "\n",
    "del df1, df2, df3, df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9523b1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more_cols = ['2_neigh_5_mean',\n",
    "#  '2_neigh_5_min',\n",
    "#  '2_neigh_5_max',\n",
    "#  '5_neigh_5_mean',\n",
    "#  '5_neigh_5_min',\n",
    "#  '5_neigh_5_max',\n",
    "#  '7_neigh_5_mean',\n",
    "#  '7_neigh_5_min',\n",
    "#  '7_neigh_5_max',\n",
    "#  '8_neigh_5_mean',\n",
    "#  '8_neigh_5_min',\n",
    "#  '8_neigh_5_max',\n",
    "#  '9_neigh_5_mean',\n",
    "#  '9_neigh_5_min',\n",
    "#  '9_neigh_5_max',\n",
    "#  '12_neigh_5_mean',\n",
    "#  '12_neigh_5_min',\n",
    "#  '12_neigh_5_max',\n",
    "#  '19_neigh_5_mean',\n",
    "#  '19_neigh_5_min',\n",
    "#  '19_neigh_5_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e09c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = features + sst_features_5 + wind_feature_5 + slp_feature_5 + precip_feature_5 + pres_feature_5 + rhum_feature_5 + slp_feature_3 + precip_feature_3 + pres_feature_3  + slp_feature_7 + rhum_feature_7 + sst_features_7 + precip_feature_7 + pres_feature_7 + wind_feature_7 + slp_feature_9 + wind_feature_9 + pres_feature_9 + precip_feature_9 + rhum_feature_9 + rhum_feature_13 + \\\n",
    "rhum_feature_time_7 + pres_feature_time_7 + precip_feature_time_7 + \\\n",
    "rhum_feature_time_14 + pres_feature_time_14 + precip_feature_time_14 + \\\n",
    "sst_features_5_lat + wind_feature_5_lat + slp_feature_5_lat + precip_feature_5_lat + pres_feature_5_lat + rhum_feature_5_lat + \\\n",
    "sst_features_5_lon + wind_feature_5_lon + slp_feature_5_lon + precip_feature_5_lon + pres_feature_5_lon + rhum_feature_5_lon + \\\n",
    "slp_feature_5_diag_pos + precip_feature_5_diag_pos + pres_feature_5_diag_pos + rhum_feature_5_diag_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce855d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = selected_cols\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64f1d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['loc_group'] = [str(i) for i in df['loc_group'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98954d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[:375734]\n",
    "test_df = df[375734:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d912979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 514/514 [00:19<00:00, 26.58it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df_by_region_list = []\n",
    "test_df_by_region_list = []\n",
    "\n",
    "for i in tqdm(range(514)):\n",
    "    train_df_by_region_list.append(train_df[train_df['loc_group'] == str(i)])\n",
    "    test_df_by_region_list.append(test_df[test_df['loc_group'] == str(i)])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0314b3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_by_region(train_df_, test_df_):\n",
    "    new_train_df = train_df_[:-61]\n",
    "    new_val_df = train_df_[-61:]\n",
    "    X_train = new_train_df[cols].values\n",
    "    y_train = new_train_df[target[0]].values\n",
    "    \n",
    "    X_val = new_val_df[cols].values\n",
    "    y_val = new_val_df[target[0]].values\n",
    "    \n",
    "    clf = CatBoostRegressor( iterations = 1000, verbose = 10, task_type = 'GPU', devices = '0')\n",
    "    clf.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
    "    \n",
    "    s = clf.predict(test_df_[cols].values)\n",
    "    return s, clf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14fac79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = features + sst_features_5 + wind_feature_5 + slp_feature_5 + precip_feature_5 + pres_feature_5 + rhum_feature_5 + slp_feature_3 + precip_feature_3 + pres_feature_3  + slp_feature_7 + rhum_feature_7 + sst_features_7 + precip_feature_7 + pres_feature_7 + wind_feature_7 + slp_feature_9 + wind_feature_9 + pres_feature_9 + precip_feature_9 + rhum_feature_9 + rhum_feature_13 + \\\n",
    "rhum_feature_time_7 + pres_feature_time_7 + precip_feature_time_7 + \\\n",
    "rhum_feature_time_14 + pres_feature_time_14 + precip_feature_time_14 + \\\n",
    "sst_features_5_lat + wind_feature_5_lat + slp_feature_5_lat + precip_feature_5_lat + pres_feature_5_lat + rhum_feature_5_lat + \\\n",
    "sst_features_5_lon + wind_feature_5_lon + slp_feature_5_lon + precip_feature_5_lon + pres_feature_5_lon + rhum_feature_5_lon + \\\n",
    "slp_feature_5_diag_pos + precip_feature_5_diag_pos + pres_feature_5_diag_pos + rhum_feature_5_diag_pos\n",
    "cols = selected_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "070365c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[cols]\n",
    "y = train_df[target[0]]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=train_df['loc_group'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a212557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.022634\n",
      "0:\tlearn: 9.6707717\ttest: 9.7083219\tbest: 9.7083219 (0)\ttotal: 5.87ms\tremaining: 29m 20s\n",
      "1000:\tlearn: 0.8799189\ttest: 0.8902421\tbest: 0.8902421 (1000)\ttotal: 5.71s\tremaining: 28m 25s\n",
      "2000:\tlearn: 0.6475407\ttest: 0.6606431\tbest: 0.6606431 (2000)\ttotal: 11.6s\tremaining: 28m 42s\n",
      "3000:\tlearn: 0.5435700\ttest: 0.5594568\tbest: 0.5594568 (3000)\ttotal: 18.1s\tremaining: 29m 52s\n",
      "4000:\tlearn: 0.4811424\ttest: 0.4992835\tbest: 0.4992835 (4000)\ttotal: 24.6s\tremaining: 30m 16s\n",
      "5000:\tlearn: 0.4370472\ttest: 0.4568592\tbest: 0.4568592 (5000)\ttotal: 30.6s\tremaining: 30m 7s\n",
      "6000:\tlearn: 0.4036904\ttest: 0.4250857\tbest: 0.4250857 (6000)\ttotal: 37s\tremaining: 30m 10s\n",
      "7000:\tlearn: 0.3770086\ttest: 0.3996870\tbest: 0.3996870 (7000)\ttotal: 43.1s\tremaining: 30m 3s\n",
      "8000:\tlearn: 0.3552226\ttest: 0.3792050\tbest: 0.3792050 (8000)\ttotal: 49.3s\tremaining: 30m\n",
      "9000:\tlearn: 0.3366904\ttest: 0.3618136\tbest: 0.3618136 (9000)\ttotal: 55.3s\tremaining: 29m 48s\n",
      "10000:\tlearn: 0.3208627\ttest: 0.3471248\tbest: 0.3471248 (10000)\ttotal: 1m 1s\tremaining: 29m 31s\n",
      "11000:\tlearn: 0.3069269\ttest: 0.3341604\tbest: 0.3341604 (11000)\ttotal: 1m 6s\tremaining: 29m 15s\n",
      "12000:\tlearn: 0.2945642\ttest: 0.3228001\tbest: 0.3228001 (12000)\ttotal: 1m 12s\tremaining: 29m 2s\n",
      "13000:\tlearn: 0.2835560\ttest: 0.3127254\tbest: 0.3127254 (13000)\ttotal: 1m 18s\tremaining: 28m 49s\n",
      "14000:\tlearn: 0.2736320\ttest: 0.3036405\tbest: 0.3036405 (14000)\ttotal: 1m 24s\tremaining: 28m 38s\n",
      "15000:\tlearn: 0.2646100\ttest: 0.2955320\tbest: 0.2955320 (15000)\ttotal: 1m 29s\tremaining: 28m 26s\n",
      "16000:\tlearn: 0.2564319\ttest: 0.2881504\tbest: 0.2881504 (16000)\ttotal: 1m 35s\tremaining: 28m 18s\n"
     ]
    }
   ],
   "source": [
    "clf = CatBoostRegressor( iterations = 300000, verbose = 1000, task_type = 'GPU', devices = '0')\n",
    "clf.fit(X_train.values, y_train.values, eval_set=[(X_val.values, y_val.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e6bd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = clf.predict(test_df[cols].values)\n",
    "output_df = pd.DataFrame(columns = ['index', 'pred'])\n",
    "output_df['index'] = [int(i) for i in test_df['index']]\n",
    "output_df['pred'] = s\n",
    "res_df = pd.read_csv('./sample_solution.csv')\n",
    "res_df = res_df.merge(output_df, how='left', on = ['index'])\n",
    "res_df['contest-tmp2m-14d__tmp2m'] = res_df['pred']\n",
    "res_df[[target[0], 'index']].to_csv('submission_strtify_training.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
