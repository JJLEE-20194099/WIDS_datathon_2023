{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "5f523266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import seaborn as sns \n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, BaggingRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from scipy.stats import norm\n",
    "import copy\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostRegressor, Pool, metrics, cv\n",
    "import xgboost as xgb\n",
    "from scipy.stats import gmean\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d5ae3645",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train_data.csv')\n",
    "test_df = pd.read_csv('./test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6710f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_nom(train, test):\n",
    "    scale = 14\n",
    "\n",
    "    train.loc[:,'lat']=round(train.lat,scale)\n",
    "    train.loc[:,'lon']=round(train.lon,scale)\n",
    "    test.loc[:,'lat']=round(test.lat,scale)\n",
    "    test.loc[:,'lon']=round(test.lon,scale)\n",
    "\n",
    "    all_df = pd.concat([train, test], axis=0)\n",
    "    all_df['loc_group'] = all_df.groupby(['lat','lon']).ngroup()\n",
    "    train = all_df.iloc[:len(train)]\n",
    "    test = all_df.iloc[len(train):].drop(target, axis=1)\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "def categorical_encode(train, test):\n",
    "    le = LabelEncoder()\n",
    "    train['climateregions__climateregion'] = le.fit_transform(train['climateregions__climateregion'])\n",
    "    test['climateregions__climateregion'] = le.transform(test['climateregions__climateregion'])\n",
    "    return train, test\n",
    "\n",
    "def creat_new_featute(df):\n",
    "    df['year'] = df['startdate'].dt.year\n",
    "    df['month'] = df['startdate'].dt.month\n",
    "    df['day_of_year'] = df['startdate'].dt.dayofyear\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2db5e549",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = location_nom(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "49359cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_map = dict()\n",
    "for i, col in enumerate(train_df['climateregions__climateregion'].unique()):\n",
    "    region_map[col] = i\n",
    "train_df['climateregions__climateregion'] = train_df['climateregions__climateregion'].map(region_map)\n",
    "test_df['climateregions__climateregion'] = test_df['climateregions__climateregion'].map(region_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "dce768c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df.drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "33bb2faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['month']=pd.DatetimeIndex(train_df['startdate']).month - 1\n",
    "train_df['day']=pd.DatetimeIndex(train_df['startdate']).day - 1\n",
    "test_df['month']=pd.DatetimeIndex(test_df['startdate']).month - 1\n",
    "test_df['day']=pd.DatetimeIndex(test_df['startdate']).day - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "1d0e420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['year']=pd.DatetimeIndex(train_df['startdate']).year\n",
    "test_df['year']=pd.DatetimeIndex(test_df['startdate']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b06633af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  9, 10, 11,  0,  1,  2,  3,  4,  5,  6,  7])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['month'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f5626791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_season(month):\n",
    "    if month == 11 or month == 0 or month == 1:\n",
    "        return 3\n",
    "    if month == 2 or month == 3 or month == 4:\n",
    "        return 0\n",
    "    if month == 5 or month == 6 or month == 7:\n",
    "        return 1\n",
    "    return 2\n",
    "train_df['season'] = train_df['month'].apply(cal_season)\n",
    "test_df['season'] = test_df['month'].apply(cal_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5c5a044f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['startdate', 'climateregions__climateregion', 'loc_group', 'month',\n",
       "       'day', 'season'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[:,train_df.dtypes!='float'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e057fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['climateregions__climateregion', 'loc_group', 'season', 'month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ecb8d302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 249 columns.\n",
      "There are 8 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_26bc3_row0_col0, #T_26bc3_row0_col1, #T_26bc3_row1_col0, #T_26bc3_row1_col1, #T_26bc3_row2_col0, #T_26bc3_row2_col1, #T_26bc3_row3_col0, #T_26bc3_row3_col1 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_26bc3_row4_col0, #T_26bc3_row5_col0 {\n",
       "  background-color: #fdc6b0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_26bc3_row4_col1, #T_26bc3_row5_col1 {\n",
       "  background-color: #fdc7b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_26bc3_row6_col0, #T_26bc3_row6_col1, #T_26bc3_row7_col0, #T_26bc3_row7_col1 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_26bc3_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Missing Values</th>\n",
       "      <th class=\"col_heading level0 col1\" >% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_26bc3_level0_row0\" class=\"row_heading level0 row0\" >nmme0-tmp2m-34w__ccsm30</th>\n",
       "      <td id=\"T_26bc3_row0_col0\" class=\"data row0 col0\" >15934</td>\n",
       "      <td id=\"T_26bc3_row0_col1\" class=\"data row0 col1\" >4.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_26bc3_level0_row1\" class=\"row_heading level0 row1\" >nmme0-prate-56w__ccsm30</th>\n",
       "      <td id=\"T_26bc3_row1_col0\" class=\"data row1 col0\" >15934</td>\n",
       "      <td id=\"T_26bc3_row1_col1\" class=\"data row1 col1\" >4.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_26bc3_level0_row2\" class=\"row_heading level0 row2\" >nmme0-prate-34w__ccsm30</th>\n",
       "      <td id=\"T_26bc3_row2_col0\" class=\"data row2 col0\" >15934</td>\n",
       "      <td id=\"T_26bc3_row2_col1\" class=\"data row2 col1\" >4.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_26bc3_level0_row3\" class=\"row_heading level0 row3\" >ccsm30</th>\n",
       "      <td id=\"T_26bc3_row3_col0\" class=\"data row3 col0\" >15934</td>\n",
       "      <td id=\"T_26bc3_row3_col1\" class=\"data row3 col1\" >4.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_26bc3_level0_row4\" class=\"row_heading level0 row4\" >nmme-tmp2m-56w__ccsm3</th>\n",
       "      <td id=\"T_26bc3_row4_col0\" class=\"data row4 col0\" >10280</td>\n",
       "      <td id=\"T_26bc3_row4_col1\" class=\"data row4 col1\" >2.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_26bc3_level0_row5\" class=\"row_heading level0 row5\" >nmme-prate-56w__ccsm3</th>\n",
       "      <td id=\"T_26bc3_row5_col0\" class=\"data row5 col0\" >10280</td>\n",
       "      <td id=\"T_26bc3_row5_col1\" class=\"data row5 col1\" >2.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_26bc3_level0_row6\" class=\"row_heading level0 row6\" >nmme-prate-34w__ccsm3</th>\n",
       "      <td id=\"T_26bc3_row6_col0\" class=\"data row6 col0\" >8738</td>\n",
       "      <td id=\"T_26bc3_row6_col1\" class=\"data row6 col1\" >2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_26bc3_level0_row7\" class=\"row_heading level0 row7\" >nmme-tmp2m-34w__ccsm3</th>\n",
       "      <td id=\"T_26bc3_row7_col0\" class=\"data row7 col0\" >8738</td>\n",
       "      <td id=\"T_26bc3_row7_col1\" class=\"data row7 col1\" >2.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f603cb24f10>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def missing_values_table(df):\n",
    "        # Total missing values by column\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values by column\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # build a table with the thw columns\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns\n",
    "\n",
    "# Missing values for training data\n",
    "missing_values_train = missing_values_table(train_df)\n",
    "missing_values_train[:20].style.background_gradient(cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "85293cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_imputing = True\n",
    "target=[\"contest-tmp2m-14d__tmp2m\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "549b8952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/hieunm/anaconda3/envs/action-env/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "train_df['source'] = 'train'\n",
    "test_df['source']  = 'test'\n",
    "df = pd.concat([train_df,test_df], 0, ignore_index=True)\n",
    "groupby_cols = ['startdate'] + cats\n",
    "df=df.sort_values(by=groupby_cols).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "4712f2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5b9aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if knn_imputing:\n",
    "    imputer = KNNImputer(n_neighbors=7)\n",
    "    cats_with_target = cats + target + ['startdate'] + ['source']\n",
    "    tmp = df[cats_with_target]\n",
    "    df = df.drop(tmp.columns, axis=1)\n",
    "    df1 = pd.DataFrame(imputer.fit_transform(df),columns = df.columns)\n",
    "\n",
    "    joblib.dump(imputer, '../models/knn_imputer.pkl')\n",
    "\n",
    "    for col in tmp.columns:\n",
    "        df[col]=tmp[col]\n",
    "    for col in df1.columns:\n",
    "        df[col] = df1[col]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "action-env",
   "language": "python",
   "name": "action-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
