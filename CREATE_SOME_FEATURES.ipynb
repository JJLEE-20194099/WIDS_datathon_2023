{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f454ea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import seaborn as sns \n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, BaggingRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from scipy.stats import norm\n",
    "import copy\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostRegressor, Pool, metrics, cv\n",
    "import xgboost as xgb\n",
    "from scipy.stats import gmean\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9994c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./no_missing_train.csv', parse_dates=[\"startdate\"])\n",
    "test_df = pd.read_csv('./no_missing_test.csv', parse_dates=[\"startdate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b459f8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "target=\"contest-tmp2m-14d__tmp2m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8857322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(actual, predicted):\n",
    "    return mean_squared_error(actual, predicted, squared=False)\n",
    "\n",
    "def location_nom(train, test):\n",
    "    scale = 14\n",
    "\n",
    "    train.loc[:,'lat']=round(train.lat,scale)\n",
    "    train.loc[:,'lon']=round(train.lon,scale)\n",
    "    test.loc[:,'lat']=round(test.lat,scale)\n",
    "    test.loc[:,'lon']=round(test.lon,scale)\n",
    "\n",
    "    all_df = pd.concat([train, test], axis=0)\n",
    "    all_df['loc_group'] = all_df.groupby(['lat','lon']).ngroup()\n",
    "    train = all_df.iloc[:len(train)]\n",
    "    test = all_df.iloc[len(train):].drop(target, axis=1)\n",
    "    \n",
    "    return train, test\n",
    "def categorical_encode(train, test):\n",
    "    le = LabelEncoder()\n",
    "    train['climateregions__climateregion'] = le.fit_transform(train['climateregions__climateregion'])\n",
    "    test['climateregions__climateregion'] = le.transform(test['climateregions__climateregion'])\n",
    "    return train, test\n",
    "\n",
    "def creat_new_featute(df):\n",
    "    df['year'] = df['startdate'].dt.year\n",
    "    df['month'] = df['startdate'].dt.month\n",
    "    df['day_of_year'] = df['startdate'].dt.dayofyear\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cfa4a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = location_nom(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3f94f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = categorical_encode(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1dec56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = creat_new_featute(train_df)\n",
    "test_df = creat_new_featute(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e6f4e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_season(df):\n",
    "  month_to_season = {\n",
    "      1: 0,\n",
    "      2: 0,\n",
    "      3: 1,\n",
    "      4: 1,\n",
    "      5: 1,\n",
    "      6: 2,\n",
    "      7: 2,\n",
    "      8: 2, \n",
    "      9: 3, \n",
    "      10: 3,\n",
    "      11: 3,\n",
    "      12: 0\n",
    "  }\n",
    "  df['season'] = df['month'].apply(lambda x: month_to_season[x])\n",
    "\n",
    "add_season(train_df)\n",
    "add_season(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a2b0d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def sin_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.sin(x / period * 2 * np.pi))\n",
    "\n",
    "\n",
    "def cos_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.cos(x / period * 2 * np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "26510a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cyclical(df):\n",
    "  df['day_of_year_sin'] = sin_transformer(365).fit_transform(df['day_of_year'])\n",
    "  df['day_of_year_cos'] = cos_transformer(365).fit_transform(df['day_of_year'])\n",
    "\n",
    "  df['month_sin'] = sin_transformer(12).fit_transform(df['month'])\n",
    "  df['month_cos'] = cos_transformer(12).fit_transform(df['month'])\n",
    "\n",
    "  df['season_sin'] = sin_transformer(4).fit_transform(df['season'])\n",
    "  df['season_cos'] = cos_transformer(4).fit_transform(df['season'])\n",
    "\n",
    "encode_cyclical(train_df)\n",
    "encode_cyclical(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75c980b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in train_df.columns:\n",
    "    if train_df[c].isnull().sum() > 0:\n",
    "        print(c, train_df[c].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb565523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main features: 240\n"
     ]
    }
   ],
   "source": [
    "exclude_cols = ['index', 'startdate']\n",
    "temporal_attrs = ['year', 'month', 'week', 'day_of_year', 'season', 'day_of_year_sin', 'day_of_year_cos','month_sin', 'month_cos', 'season_sin', 'season_cos']\n",
    "loc_attrs = ['lat', 'lon', 'loc_group']\n",
    "embedding_attrs = ['climateregions__climateregion']\n",
    "target=[\"contest-tmp2m-14d__tmp2m\"]\n",
    "main_attrs = [c for c in train_df.columns if c not in exclude_cols and c not in temporal_attrs and c not in loc_attrs and c not in target and c not in embedding_attrs]\n",
    "print(\"Main features:\", len(main_attrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99e5bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('./new_train.csv', index=False)\n",
    "test_df.to_csv('./new_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "action-env",
   "language": "python",
   "name": "action-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
