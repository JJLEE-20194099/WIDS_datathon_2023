{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65ae0520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import seaborn as sns \n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, BaggingRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from scipy.stats import norm\n",
    "import copy\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostRegressor, Pool, metrics, cv\n",
    "import xgboost as xgb\n",
    "from scipy.stats import gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c23190af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./n_train.csv')\n",
    "test_df = pd.read_csv('./n_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c585beb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main features: 240\n"
     ]
    }
   ],
   "source": [
    "exclude_cols = ['index', 'startdate']\n",
    "temporal_attrs = ['year', 'quarter', 'month', 'week', 'dayofyear', 'season', 'day_of_year_sin', 'day_of_year_cos', 'week_sin', 'week_cos', 'month_sin', 'month_cos', 'season_sin', 'season_cos', 'quarter_sin', 'quarter_cos']\n",
    "loc_attrs = ['lat', 'lon', 'loc_group']\n",
    "embedding_attrs = ['climateregions__climateregion']\n",
    "target=[\"contest-tmp2m-14d__tmp2m\"]\n",
    "main_attrs = [c for c in train_df.columns if c not in exclude_cols and c not in temporal_attrs and c not in loc_attrs and c not in target and c not in embedding_attrs]\n",
    "print(\"Main features:\", len(main_attrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50b17a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_independent_corr = train_df[main_attrs + temporal_attrs + loc_attrs + embedding_attrs].corr()\n",
    "train_seleted_corr_columns = np.full((train_independent_corr.shape[0],), True, dtype=bool)\n",
    "for i in range(train_independent_corr.shape[0]):\n",
    "    for j in range(i + 1, train_independent_corr.shape[0]):\n",
    "        if train_independent_corr.iloc[i, j] >= 0.85:\n",
    "            \n",
    "            if train_seleted_corr_columns[j]:\n",
    "                train_seleted_corr_columns[j] = False\n",
    "train_selected_columns = train_df[main_attrs + temporal_attrs + loc_attrs + embedding_attrs].columns[train_seleted_corr_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cebce45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['contest-pevpr-sfc-gauss-14d__pevpr', 'nmme0-tmp2m-34w__cancm30', 'contest-wind-h10-14d__wind-hgt-10', 'contest-rhum-sig995-14d__rhum', 'nmme-prate-34w__cancm3', 'nmme-prate-34w__ccsm3', 'nmme-prate-34w__ccsm4', 'nmme-prate-34w__cfsv2', 'nmme-prate-34w__gfdl', 'nmme-prate-34w__gfdlflora', 'nmme-prate-34w__nasa', 'nmme0-prate-56w__cancm30', 'nmme0-prate-56w__cancm40', 'nmme0-prate-56w__ccsm30', 'nmme0-prate-56w__ccsm40', 'nmme0-prate-56w__cfsv20', 'nmme0-prate-56w__gfdlflora0', 'nmme0-prate-56w__gfdl0', 'nmme0-prate-56w__nasa0', 'nmme0-prate-34w__cancm40', 'contest-slp-14d__slp', 'contest-wind-vwnd-925-14d__wind-vwnd-925', 'contest-pres-sfc-gauss-14d__pres', 'contest-wind-uwnd-250-14d__wind-uwnd-250', 'contest-prwtr-eatm-14d__prwtr', 'contest-wind-vwnd-250-14d__wind-vwnd-250', 'contest-precip-14d__precip', 'contest-wind-h850-14d__wind-hgt-850', 'contest-wind-uwnd-925-14d__wind-uwnd-925', 'elevation__elevation', 'wind-vwnd-250-2010-1', 'wind-vwnd-250-2010-2', 'wind-vwnd-250-2010-3', 'wind-vwnd-250-2010-4', 'wind-vwnd-250-2010-5', 'wind-vwnd-250-2010-6', 'wind-vwnd-250-2010-7', 'wind-vwnd-250-2010-8', 'wind-vwnd-250-2010-9', 'wind-vwnd-250-2010-10', 'wind-vwnd-250-2010-11', 'wind-vwnd-250-2010-12', 'wind-vwnd-250-2010-13', 'wind-vwnd-250-2010-14', 'wind-vwnd-250-2010-15', 'wind-vwnd-250-2010-16', 'wind-vwnd-250-2010-17', 'wind-vwnd-250-2010-18', 'wind-vwnd-250-2010-19', 'wind-vwnd-250-2010-20', 'wind-uwnd-250-2010-2', 'wind-uwnd-250-2010-3', 'wind-uwnd-250-2010-4', 'wind-uwnd-250-2010-5', 'wind-uwnd-250-2010-6', 'wind-uwnd-250-2010-7', 'wind-uwnd-250-2010-8', 'wind-uwnd-250-2010-9', 'wind-uwnd-250-2010-10', 'wind-uwnd-250-2010-11', 'wind-uwnd-250-2010-12', 'wind-uwnd-250-2010-13', 'wind-uwnd-250-2010-14', 'wind-uwnd-250-2010-15', 'wind-uwnd-250-2010-16', 'wind-uwnd-250-2010-17', 'wind-uwnd-250-2010-18', 'wind-uwnd-250-2010-19', 'wind-uwnd-250-2010-20', 'mjo1d__phase', 'mjo1d__amplitude', 'mei__mei', 'mei__nip', 'wind-hgt-850-2010-1', 'wind-hgt-850-2010-2', 'wind-hgt-850-2010-3', 'wind-hgt-850-2010-4', 'wind-hgt-850-2010-5', 'wind-hgt-850-2010-6', 'wind-hgt-850-2010-7', 'wind-hgt-850-2010-8', 'wind-hgt-850-2010-9', 'wind-hgt-850-2010-10', 'sst-2010-2', 'sst-2010-3', 'sst-2010-4', 'sst-2010-5', 'sst-2010-6', 'sst-2010-7', 'sst-2010-8', 'sst-2010-9', 'sst-2010-10', 'wind-hgt-500-2010-2', 'wind-hgt-500-2010-3', 'wind-hgt-500-2010-4', 'wind-hgt-500-2010-5', 'wind-hgt-500-2010-6', 'wind-hgt-500-2010-7', 'wind-hgt-500-2010-8', 'wind-hgt-500-2010-9', 'wind-hgt-500-2010-10', 'wind-uwnd-925-2010-2', 'wind-uwnd-925-2010-3', 'wind-uwnd-925-2010-4', 'wind-uwnd-925-2010-5', 'wind-uwnd-925-2010-6', 'wind-uwnd-925-2010-7', 'wind-uwnd-925-2010-8', 'wind-uwnd-925-2010-9', 'wind-uwnd-925-2010-10', 'wind-uwnd-925-2010-11', 'wind-uwnd-925-2010-12', 'wind-uwnd-925-2010-13', 'wind-uwnd-925-2010-14', 'wind-uwnd-925-2010-15', 'wind-uwnd-925-2010-16', 'wind-uwnd-925-2010-17', 'wind-uwnd-925-2010-18', 'wind-uwnd-925-2010-19', 'wind-uwnd-925-2010-20', 'wind-hgt-10-2010-2', 'wind-hgt-10-2010-3', 'wind-hgt-10-2010-4', 'wind-hgt-10-2010-5', 'wind-hgt-10-2010-6', 'wind-hgt-10-2010-7', 'wind-hgt-10-2010-8', 'wind-hgt-10-2010-9', 'wind-hgt-10-2010-10', 'wind-hgt-100-2010-3', 'wind-hgt-100-2010-4', 'wind-hgt-100-2010-5', 'wind-hgt-100-2010-6', 'wind-hgt-100-2010-7', 'wind-hgt-100-2010-8', 'wind-hgt-100-2010-9', 'wind-hgt-100-2010-10', 'wind-vwnd-925-2010-2', 'wind-vwnd-925-2010-3', 'wind-vwnd-925-2010-4', 'wind-vwnd-925-2010-5', 'wind-vwnd-925-2010-6', 'wind-vwnd-925-2010-7', 'wind-vwnd-925-2010-8', 'wind-vwnd-925-2010-9', 'wind-vwnd-925-2010-10', 'wind-vwnd-925-2010-11', 'wind-vwnd-925-2010-12', 'wind-vwnd-925-2010-13', 'wind-vwnd-925-2010-14', 'wind-vwnd-925-2010-15', 'wind-vwnd-925-2010-16', 'wind-vwnd-925-2010-17', 'wind-vwnd-925-2010-18', 'wind-vwnd-925-2010-19', 'wind-vwnd-925-2010-20', 'season', 'lat', 'lon', 'climateregions__climateregion']\n"
     ]
    }
   ],
   "source": [
    "out_cols = ['icec-2010-1',\n",
    " 'icec-2010-2',\n",
    " 'icec-2010-3',\n",
    " 'icec-2010-4',\n",
    " 'icec-2010-5',\n",
    " 'icec-2010-6',\n",
    " 'icec-2010-7',\n",
    " 'icec-2010-8',\n",
    " 'icec-2010-9',\n",
    " 'icec-2010-10',\n",
    " 'year',\n",
    " 'quarter',\n",
    " 'month_cos',\n",
    " 'quarter_sin',\n",
    " 'quarter_cos']\n",
    "features = [c for c in train_selected_columns if c not in out_cols]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8905cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingCVRegressorRetrained(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, regressors, meta_regressor, n_folds=2, use_features_in_secondary=False):\n",
    "        self.regressors = regressors\n",
    "        self.meta_regressor = meta_regressor\n",
    "        self.n_folds = n_folds\n",
    "        self.use_features_in_secondary = use_features_in_secondary\n",
    "        self.regr_ = [clone(x) for x in self.regressors]\n",
    "        self.meta_regr_ = clone(self.meta_regressor)\n",
    "\n",
    "    def fit(self, train, y):\n",
    "        if type(train) == pd.core.frame.DataFrame:            \n",
    "            X = copy.deepcopy(train).values\n",
    "            #ADD more features for meta regressor\n",
    "            #train = add_features(train)\n",
    "        elif type(train) == np.ndarray:            \n",
    "            X = copy.deepcopy(train)\n",
    "\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True)\n",
    "\n",
    "\n",
    "        # Create out-of-fold predictions for training meta-model\n",
    "        for i, regr in enumerate(self.regr_):\n",
    "            for train_idx, holdout_idx in kfold.split(X, y):\n",
    "                instance = clone(regr)\n",
    "                instance.fit(X[train_idx], y[train_idx])\n",
    "                out_of_fold_predictions[holdout_idx, i] = instance.predict(X[holdout_idx])\n",
    "       \n",
    "        # Retrain base models on all data\n",
    "        all_predictions = np.zeros((X.shape[0], len(self.regressors)))\n",
    "        for i, regr in enumerate(self.regr_):\n",
    "            regr.fit(X, y)\n",
    "            all_predictions[:, i] = regr.predict(X)\n",
    "        \n",
    "        # Train meta-model\n",
    "        #ADD more features\n",
    "            X = train.values\n",
    "        #X = train.values\n",
    "        \n",
    "        if self.use_features_in_secondary:\n",
    "            self.meta_regr_.fit(np.hstack((X, out_of_fold_predictions)), y)\n",
    "        else:\n",
    "            self.meta_regr_.fit(out_of_fold_predictions, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, test):\n",
    "        if type(test) == pd.core.frame.DataFrame:\n",
    "            X = copy.deepcopy(test).values\n",
    "        elif type(test) == np.ndarray:            \n",
    "            X = copy.deepcopy(test)\n",
    "        \n",
    "        meta_features = np.column_stack([\n",
    "            regr.predict(X) for regr in self.regr_\n",
    "        ])\n",
    "        \n",
    "        if type(test) == pd.core.frame.DataFrame:\n",
    "            #ADD more features      \n",
    "            X = test.values\n",
    "\n",
    "        if self.use_features_in_secondary:\n",
    "            return self.meta_regr_.predict(np.hstack((X, meta_features)))\n",
    "        else:\n",
    "            return self.meta_regr_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6be889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df[features]\n",
    "test = test_df[features]\n",
    "\n",
    "y_train = train_df[target[0]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c0ec6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "en = make_pipeline(RobustScaler(), SelectFromModel(Lasso(alpha=0.03)), ElasticNet(alpha=0.001, l1_ratio=0.1))\n",
    "    \n",
    "cat = CatBoostRegressor(iterations=4900, verbose=200)\n",
    "\n",
    "adb = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4), n_estimators=300, random_state=2017)\n",
    "\n",
    "bag = BaggingRegressor(DecisionTreeRegressor(max_depth=4), n_estimators=300, random_state=2017, verbose=200)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=250, n_jobs=4, min_samples_split=25, min_samples_leaf=25, verbose=200)\n",
    "\n",
    "et = ExtraTreesRegressor(n_estimators=250, n_jobs=4, min_samples_split=25, min_samples_leaf=25, verbose=200)\n",
    "\n",
    "gbr = GradientBoostingRegressor(loss='huber', learning_rate=0.1, verbose=200, n_estimators=350, min_samples_split=25, min_samples_leaf=25)\n",
    "\n",
    "xgbm = xgb.sklearn.XGBRegressor(max_depth=6, learning_rate=0.005, subsample=0.6,\n",
    "                                objective='reg:linear', n_estimators=1000, verbose=200)\n",
    "\n",
    "nn = MLPRegressor(hidden_layer_sizes=(200, 400, 50), random_state =2017, early_stopping=True, verbose=200)\n",
    "\n",
    "svm = SVR(kernel='poly', degree=3, gamma='auto', coef0=0.0, tol=0.001, C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=True, max_iter=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51518def",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_val_score(cat, train.values, y_train, cv=5, scoring='neg_mean_squared_error')#0.673187 (0.066807)\n",
    "print(\"cat boost regressor score: {:4f} ({:4f})\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bcd786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1          37.5992           93.62m\n",
      "         2          31.7201           75.62m\n",
      "         3          26.9288           68.04m\n",
      "         4          22.9560           63.91m\n",
      "         5          19.7134           61.59m\n",
      "         6          17.0372           59.59m\n",
      "         7          14.8279           58.45m\n",
      "         8          12.9184           57.57m\n",
      "         9          11.3425           57.03m\n",
      "        10          10.0332           56.40m\n",
      "        11           8.9431           55.86m\n",
      "        12           8.0546           55.40m\n",
      "        13           7.2884           54.81m\n",
      "        14           6.6528           54.20m\n",
      "        15           6.1081           53.70m\n",
      "        16           5.6096           53.27m\n",
      "        17           5.1953           52.93m\n",
      "        18           4.8493           52.59m\n",
      "        19           4.5339           52.28m\n",
      "        20           4.2724           51.93m\n",
      "        21           4.0299           51.64m\n",
      "        22           3.8241           51.37m\n",
      "        23           3.6481           51.12m\n",
      "        24           3.4849           50.88m\n",
      "        25           3.3460           50.62m\n",
      "        26           3.2149           50.42m\n",
      "        27           3.0985           50.22m\n",
      "        28           2.9992           49.98m\n",
      "        29           2.8994           49.77m\n",
      "        30           2.8114           49.56m\n",
      "        31           2.7295           49.41m\n",
      "        32           2.6594           49.19m\n",
      "        33           2.5938           49.00m\n",
      "        34           2.5341           48.82m\n",
      "        35           2.4838           48.65m\n",
      "        36           2.4333           48.48m\n",
      "        37           2.3889           48.30m\n",
      "        38           2.3503           48.15m\n",
      "        39           2.3033           47.96m\n",
      "        40           2.2532           47.78m\n",
      "        41           2.2188           47.63m\n",
      "        42           2.1814           47.48m\n",
      "        43           2.1418           47.32m\n",
      "        44           2.1063           47.13m\n",
      "        45           2.0768           46.97m\n",
      "        46           2.0546           46.80m\n",
      "        47           2.0302           46.62m\n",
      "        48           2.0036           46.45m\n",
      "        49           1.9800           46.25m\n",
      "        50           1.9534           46.07m\n",
      "        51           1.9375           45.92m\n",
      "        52           1.9133           45.73m\n",
      "        53           1.8901           45.56m\n",
      "        54           1.8744           45.41m\n",
      "        55           1.8568           45.21m\n",
      "        56           1.8395           45.05m\n",
      "        57           1.8263           44.88m\n",
      "        58           1.8109           44.73m\n",
      "        59           1.7897           44.57m\n",
      "        60           1.7753           44.38m\n",
      "        61           1.7606           44.22m\n",
      "        62           1.7476           44.01m\n",
      "        63           1.7361           43.87m\n",
      "        64           1.7268           43.68m\n",
      "        65           1.7153           43.49m\n",
      "        66           1.6921           43.29m\n",
      "        67           1.6804           43.10m\n",
      "        68           1.6711           42.92m\n",
      "        69           1.6629           42.74m\n",
      "        70           1.6492           42.58m\n",
      "        71           1.6416           42.46m\n",
      "        72           1.6298           42.29m\n",
      "        73           1.6207           42.26m\n",
      "        74           1.6108           42.10m\n",
      "        75           1.6036           41.95m\n",
      "        76           1.5939           41.77m\n",
      "        77           1.5878           41.60m\n",
      "        78           1.5702           41.43m\n",
      "        79           1.5574           41.56m\n",
      "        80           1.5464           41.42m\n",
      "        81           1.5396           41.25m\n",
      "        82           1.5319           41.09m\n",
      "        83           1.5177           40.90m\n",
      "        84           1.5093           40.72m\n",
      "        85           1.5007           40.54m\n",
      "        86           1.4951           40.37m\n",
      "        87           1.4895           40.42m\n",
      "        88           1.4807           40.46m\n",
      "        89           1.4718           40.50m\n",
      "        90           1.4645           40.55m\n",
      "        91           1.4569           40.59m\n",
      "        92           1.4448           40.58m\n",
      "        93           1.4385           40.58m\n",
      "        94           1.4305           40.57m\n",
      "        95           1.4248           40.56m\n",
      "        96           1.4135           40.54m\n",
      "        97           1.4082           40.54m\n",
      "        98           1.3994           40.54m\n",
      "        99           1.3912           40.52m\n",
      "       100           1.3837           40.51m\n",
      "       101           1.3774           40.51m\n",
      "       102           1.3703           40.48m\n",
      "       103           1.3607           40.43m\n",
      "       104           1.3547           40.41m\n",
      "       105           1.3490           40.38m\n",
      "       106           1.3442           40.33m\n",
      "       107           1.3385           40.28m\n",
      "       108           1.3314           40.23m\n",
      "       109           1.3277           40.19m\n",
      "       110           1.3218           40.15m\n",
      "       111           1.3162           40.10m\n",
      "       112           1.3092           40.05m\n",
      "       113           1.3043           40.02m\n",
      "       114           1.3009           39.96m\n",
      "       115           1.2959           39.90m\n",
      "       116           1.2913           39.83m\n",
      "       117           1.2863           39.77m\n",
      "       118           1.2819           39.69m\n",
      "       119           1.2774           39.61m\n",
      "       120           1.2732           39.53m\n",
      "       121           1.2676           39.46m\n",
      "       122           1.2640           39.39m\n",
      "       123           1.2589           39.31m\n",
      "       124           1.2529           39.24m\n",
      "       125           1.2501           39.15m\n",
      "       126           1.2448           39.07m\n",
      "       127           1.2398           38.97m\n",
      "       128           1.2353           38.88m\n",
      "       129           1.2298           38.78m\n",
      "       130           1.2239           38.68m\n",
      "       131           1.2192           38.58m\n",
      "       132           1.2149           38.48m\n",
      "       133           1.2093           38.38m\n",
      "       134           1.2053           38.26m\n",
      "       135           1.2027           38.17m\n",
      "       136           1.1990           38.07m\n",
      "       137           1.1948           37.96m\n",
      "       138           1.1904           37.86m\n",
      "       139           1.1869           37.74m\n",
      "       140           1.1824           37.61m\n",
      "       141           1.1790           37.50m\n",
      "       142           1.1747           37.38m\n",
      "       143           1.1676           37.26m\n",
      "       144           1.1600           37.14m\n",
      "       145           1.1568           37.02m\n",
      "       146           1.1548           36.90m\n",
      "       147           1.1509           36.77m\n",
      "       148           1.1477           36.65m\n",
      "       149           1.1402           36.51m\n",
      "       150           1.1369           36.37m\n",
      "       151           1.1327           36.21m\n",
      "       152           1.1296           36.08m\n",
      "       153           1.1252           35.94m\n",
      "       154           1.1172           35.81m\n",
      "       155           1.1123           35.67m\n",
      "       156           1.1092           35.54m\n",
      "       157           1.1014           35.39m\n",
      "       158           1.0949           35.25m\n",
      "       159           1.0877           35.11m\n",
      "       160           1.0849           34.97m\n",
      "       161           1.0806           34.82m\n",
      "       162           1.0780           34.68m\n",
      "       163           1.0749           34.53m\n",
      "       164           1.0720           34.39m\n",
      "       165           1.0678           34.24m\n",
      "       166           1.0642           34.10m\n",
      "       167           1.0611           33.95m\n",
      "       168           1.0580           33.76m\n",
      "       169           1.0559           33.54m\n",
      "       170           1.0525           33.30m\n",
      "       171           1.0500           33.07m\n",
      "       172           1.0472           32.85m\n",
      "       173           1.0442           32.63m\n",
      "       174           1.0384           32.40m\n",
      "       175           1.0354           32.18m\n",
      "       176           1.0324           31.97m\n",
      "       177           1.0292           31.74m\n",
      "       178           1.0248           31.51m\n",
      "       179           1.0220           31.29m\n",
      "       180           1.0192           31.06m\n",
      "       181           1.0168           30.84m\n",
      "       182           1.0143           30.62m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       183           1.0121           30.41m\n",
      "       184           1.0101           30.20m\n",
      "       185           1.0080           30.69m\n",
      "       186           1.0034           30.47m\n",
      "       187           1.0004           30.25m\n",
      "       188           0.9962           30.02m\n",
      "       189           0.9936           29.82m\n",
      "       190           0.9892           29.66m\n",
      "       191           0.9869           29.51m\n",
      "       192           0.9851           29.35m\n",
      "       193           0.9828           29.20m\n",
      "       194           0.9798           29.04m\n",
      "       195           0.9782           28.88m\n",
      "       196           0.9762           28.73m\n",
      "       197           0.9726           28.57m\n",
      "       198           0.9666           28.40m\n",
      "       199           0.9643           28.24m\n",
      "       200           0.9616           28.07m\n",
      "       201           0.9584           27.90m\n",
      "       202           0.9559           27.73m\n",
      "       203           0.9543           27.56m\n",
      "       204           0.9520           27.40m\n",
      "       205           0.9500           27.23m\n",
      "       206           0.9482           27.06m\n",
      "       207           0.9456           26.90m\n",
      "       208           0.9431           26.74m\n",
      "       209           0.9394           26.57m\n",
      "       210           0.9367           26.41m\n",
      "       211           0.9349           26.25m\n",
      "       212           0.9325           26.08m\n",
      "       213           0.9300           25.91m\n",
      "       214           0.9278           25.74m\n",
      "       215           0.9256           25.58m\n",
      "       216           0.9231           25.41m\n",
      "       217           0.9211           25.24m\n",
      "       218           0.9189           25.09m\n",
      "       219           0.9165           24.93m\n",
      "       220           0.9136           24.75m\n",
      "       221           0.9109           24.58m\n",
      "       222           0.9090           24.40m\n",
      "       223           0.9057           24.23m\n",
      "       224           0.9041           24.05m\n",
      "       225           0.9012           23.88m\n",
      "       226           0.8981           23.71m\n",
      "       227           0.8961           23.53m\n",
      "       228           0.8950           23.36m\n",
      "       229           0.8930           23.18m\n",
      "       230           0.8901           23.02m\n",
      "       231           0.8888           22.88m\n",
      "       232           0.8874           22.70m\n",
      "       233           0.8853           22.52m\n",
      "       234           0.8809           22.35m\n",
      "       235           0.8794           22.17m\n",
      "       236           0.8769           21.99m\n",
      "       237           0.8749           21.81m\n",
      "       238           0.8730           21.63m\n",
      "       239           0.8709           21.45m\n",
      "       240           0.8686           21.27m\n",
      "       241           0.8656           21.08m\n",
      "       242           0.8641           20.90m\n",
      "       243           0.8594           20.72m\n",
      "       244           0.8575           20.54m\n",
      "       245           0.8550           20.35m\n",
      "       246           0.8531           20.17m\n",
      "       247           0.8485           19.99m\n",
      "       248           0.8463           19.80m\n",
      "       249           0.8445           19.62m\n",
      "       250           0.8421           19.43m\n",
      "       251           0.8392           19.25m\n",
      "       252           0.8356           19.06m\n",
      "       253           0.8334           18.88m\n",
      "       254           0.8320           18.69m\n",
      "       255           0.8311           18.51m\n",
      "       256           0.8298           18.32m\n",
      "       257           0.8279           18.13m\n",
      "       258           0.8259           17.95m\n",
      "       259           0.8245           17.76m\n",
      "       260           0.8221           17.57m\n",
      "       261           0.8205           17.39m\n",
      "       262           0.8184           17.20m\n",
      "       263           0.8160           17.01m\n",
      "       264           0.8148           16.82m\n",
      "       265           0.8137           16.64m\n",
      "       266           0.8127           16.45m\n",
      "       267           0.8111           16.26m\n",
      "       268           0.8087           16.06m\n",
      "       269           0.8052           15.85m\n",
      "       270           0.8017           15.64m\n",
      "       271           0.8001           15.43m\n",
      "       272           0.7991           15.22m\n",
      "       273           0.7983           15.02m\n",
      "       274           0.7976           14.81m\n",
      "       275           0.7960           14.60m\n",
      "       276           0.7947           14.39m\n",
      "       277           0.7925           14.19m\n",
      "       278           0.7916           13.98m\n",
      "       279           0.7902           13.77m\n",
      "       280           0.7881           13.57m\n",
      "       281           0.7863           13.36m\n",
      "       282           0.7850           13.15m\n",
      "       283           0.7835           12.96m\n",
      "       284           0.7811           12.78m\n",
      "       285           0.7799           12.59m\n",
      "       286           0.7784           12.41m\n",
      "       287           0.7774           12.22m\n",
      "       288           0.7765           12.03m\n",
      "       289           0.7751           11.84m\n",
      "       290           0.7717           11.65m\n",
      "       291           0.7705           11.46m\n",
      "       292           0.7697           11.28m\n",
      "       293           0.7684           11.09m\n",
      "       294           0.7666           10.90m\n",
      "       295           0.7650           10.71m\n",
      "       296           0.7635           10.52m\n",
      "       297           0.7619           10.33m\n",
      "       298           0.7608           10.14m\n",
      "       299           0.7577            9.95m\n",
      "       300           0.7561            9.76m\n",
      "       301           0.7541            9.57m\n",
      "       302           0.7514            9.38m\n",
      "       303           0.7505            9.19m\n",
      "       304           0.7486            9.00m\n",
      "       305           0.7457            8.80m\n",
      "       306           0.7437            8.61m\n",
      "       307           0.7426            8.42m\n",
      "       308           0.7411            8.23m\n",
      "       309           0.7386            8.04m\n",
      "       310           0.7372            7.84m\n",
      "       311           0.7363            7.65m\n",
      "       312           0.7349            7.46m\n",
      "       313           0.7339            7.26m\n",
      "       314           0.7328            7.07m\n",
      "       315           0.7315            6.87m\n",
      "       316           0.7304            6.68m\n",
      "       317           0.7288            6.49m\n",
      "       318           0.7279            6.29m\n",
      "       319           0.7264            6.10m\n",
      "       320           0.7242            5.90m\n",
      "       321           0.7233            5.71m\n",
      "       322           0.7221            5.51m\n",
      "       323           0.7206            5.32m\n",
      "       324           0.7194            5.12m\n",
      "       325           0.7174            4.93m\n",
      "       326           0.7164            4.73m\n",
      "       327           0.7156            4.54m\n",
      "       328           0.7144            4.34m\n",
      "       329           0.7130            4.15m\n",
      "       330           0.7109            3.95m\n",
      "       331           0.7098            3.76m\n",
      "       332           0.7091            3.56m\n",
      "       333           0.7078            3.36m\n",
      "       334           0.7064            3.17m\n",
      "       335           0.7052            2.97m\n",
      "       336           0.7036            2.77m\n",
      "       337           0.7022            2.58m\n",
      "       338           0.7008            2.38m\n",
      "       339           0.6999            2.18m\n",
      "       340           0.6993            1.98m\n",
      "       341           0.6984            1.79m\n",
      "       342           0.6977            1.59m\n",
      "       343           0.6968            1.39m\n",
      "       344           0.6955            1.19m\n",
      "       345           0.6946           59.62s\n",
      "       346           0.6936           47.71s\n",
      "       347           0.6927           35.80s\n",
      "       348           0.6915           23.87s\n",
      "       349           0.6895           11.94s\n",
      "       350           0.6882            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1          41.7331           77.13m\n",
      "         2          35.1897           77.25m\n",
      "         3          29.8197           77.12m\n",
      "         4          25.3481           76.03m\n",
      "         5          21.6867           75.34m\n",
      "         6          18.6486           75.43m\n",
      "         7          16.1269           76.82m\n",
      "         8          14.0313           76.65m\n",
      "         9          12.3135           76.42m\n",
      "        10          10.8722           75.97m\n",
      "        11           9.6598           75.53m\n",
      "        12           8.6360           75.18m\n",
      "        13           7.7597           74.74m\n",
      "        14           7.0049           74.26m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        15           6.4032           73.99m\n",
      "        16           5.8676           73.64m\n",
      "        17           5.4151           73.42m\n",
      "        18           5.0270           73.08m\n",
      "        19           4.7061           72.89m\n",
      "        20           4.4312           72.67m\n",
      "        21           4.1815           72.35m\n",
      "        22           3.9517           72.04m\n",
      "        23           3.7672           71.76m\n",
      "        24           3.5909           71.52m\n",
      "        25           3.4448           71.26m\n",
      "        26           3.3024           71.04m\n",
      "        27           3.1811           70.89m\n",
      "        28           3.0675           71.50m\n",
      "        29           2.9729           71.46m\n",
      "        30           2.8811           71.46m\n",
      "        31           2.8010           71.58m\n",
      "        32           2.7309           71.53m\n",
      "        33           2.6620           71.29m\n",
      "        34           2.6026           71.07m\n",
      "        35           2.5440           70.84m\n",
      "        36           2.4783           70.57m\n",
      "        37           2.4301           70.35m\n",
      "        38           2.3708           70.09m\n",
      "        39           2.3291           69.85m\n",
      "        40           2.2805           69.58m\n",
      "        41           2.2315           69.32m\n",
      "        42           2.1986           69.11m\n",
      "        43           2.1641           68.89m\n",
      "        44           2.1320           68.66m\n",
      "        45           2.1037           68.35m\n",
      "        46           2.0721           68.12m\n",
      "        47           2.0520           67.90m\n",
      "        48           2.0196           67.63m\n",
      "        49           1.9952           67.43m\n",
      "        50           1.9632           67.18m\n",
      "        51           1.9441           66.93m\n",
      "        52           1.9254           66.67m\n",
      "        53           1.9030           66.41m\n",
      "        54           1.8853           66.18m\n",
      "        55           1.8662           65.93m\n",
      "        56           1.8518           65.73m\n",
      "        57           1.8356           65.51m\n",
      "        58           1.8222           65.29m\n",
      "        59           1.8083           65.04m\n",
      "        60           1.7891           64.79m\n",
      "        61           1.7716           64.54m\n",
      "        62           1.7549           64.26m\n",
      "        63           1.7403           64.00m\n",
      "        64           1.7311           63.75m\n",
      "        65           1.7228           63.50m\n",
      "        66           1.7136           63.26m\n",
      "        67           1.7038           62.97m\n",
      "        68           1.6885           62.72m\n",
      "        69           1.6757           62.50m\n",
      "        70           1.6664           62.28m\n",
      "        71           1.6582           62.06m\n",
      "        72           1.6446           61.86m\n",
      "        73           1.6374           61.69m\n",
      "        74           1.6258           61.49m\n",
      "        75           1.6154           61.30m\n",
      "        76           1.6063           61.09m\n",
      "        77           1.5929           60.89m\n",
      "        78           1.5857           60.71m\n",
      "        79           1.5794           60.52m\n",
      "        80           1.5705           60.32m\n",
      "        81           1.5646           60.13m\n",
      "        82           1.5562           59.95m\n",
      "        83           1.5448           59.76m\n",
      "        84           1.5330           59.54m\n",
      "        85           1.5232           59.34m\n",
      "        86           1.5141           59.12m\n",
      "        87           1.5042           58.93m\n",
      "        88           1.4966           58.74m\n",
      "        89           1.4911           58.50m\n",
      "        90           1.4832           58.06m\n",
      "        91           1.4743           57.60m\n",
      "        92           1.4657           57.15m\n",
      "        93           1.4590           56.73m\n",
      "        94           1.4535           56.31m\n",
      "        95           1.4471           55.89m\n",
      "        96           1.4429           55.50m\n",
      "        97           1.4375           55.09m\n",
      "        98           1.4309           54.70m\n",
      "        99           1.4239           54.30m\n",
      "       100           1.4085           53.91m\n",
      "       101           1.4021           53.52m\n",
      "       102           1.3974           53.15m\n",
      "       103           1.3898           52.78m\n",
      "       104           1.3850           52.41m\n",
      "       105           1.3812           52.05m\n",
      "       106           1.3753           51.68m\n",
      "       107           1.3695           51.32m\n",
      "       108           1.3622           50.97m\n",
      "       109           1.3523           50.61m\n",
      "       110           1.3464           50.27m\n",
      "       111           1.3409           49.93m\n",
      "       112           1.3336           49.59m\n",
      "       113           1.3289           49.25m\n",
      "       114           1.3244           48.92m\n",
      "       115           1.3172           48.60m\n",
      "       116           1.3111           48.27m\n",
      "       117           1.3055           47.94m\n",
      "       118           1.3008           47.62m\n",
      "       119           1.2951           47.31m\n",
      "       120           1.2873           46.98m\n",
      "       121           1.2817           46.67m\n",
      "       122           1.2786           46.36m\n",
      "       123           1.2744           46.06m\n",
      "       124           1.2701           45.76m\n",
      "       125           1.2660           45.46m\n",
      "       126           1.2582           45.17m\n",
      "       127           1.2529           44.87m\n",
      "       128           1.2468           44.57m\n",
      "       129           1.2427           44.28m\n",
      "       130           1.2392           43.99m\n",
      "       131           1.2341           43.71m\n",
      "       132           1.2293           43.42m\n",
      "       133           1.2181           43.13m\n",
      "       134           1.2078           42.84m\n",
      "       135           1.1951           42.56m\n",
      "       136           1.1913           42.29m\n",
      "       137           1.1887           42.01m\n",
      "       138           1.1859           41.74m\n",
      "       139           1.1835           41.47m\n",
      "       140           1.1744           41.19m\n",
      "       141           1.1702           40.91m\n",
      "       142           1.1652           40.64m\n",
      "       143           1.1614           40.37m\n",
      "       144           1.1579           40.11m\n",
      "       145           1.1545           39.84m\n",
      "       146           1.1461           39.58m\n",
      "       147           1.1397           39.32m\n",
      "       148           1.1359           39.06m\n",
      "       149           1.1296           38.80m\n",
      "       150           1.1262           38.55m\n",
      "       151           1.1217           38.30m\n",
      "       152           1.1174           38.05m\n",
      "       153           1.1146           37.80m\n",
      "       154           1.1119           37.56m\n",
      "       155           1.1087           37.31m\n",
      "       156           1.1035           37.07m\n",
      "       157           1.0999           36.82m\n",
      "       158           1.0966           36.58m\n",
      "       159           1.0928           36.33m\n",
      "       160           1.0899           36.08m\n",
      "       161           1.0871           35.85m\n",
      "       162           1.0843           35.61m\n",
      "       163           1.0811           35.37m\n",
      "       164           1.0785           35.13m\n",
      "       165           1.0750           34.90m\n",
      "       166           1.0729           34.67m\n",
      "       167           1.0691           34.44m\n",
      "       168           1.0658           34.21m\n",
      "       169           1.0623           34.00m\n",
      "       170           1.0581           33.80m\n",
      "       171           1.0547           33.58m\n",
      "       172           1.0514           33.34m\n",
      "       173           1.0485           33.12m\n",
      "       174           1.0434           32.89m\n",
      "       175           1.0413           32.67m\n",
      "       176           1.0352           32.44m\n",
      "       177           1.0318           32.22m\n",
      "       178           1.0294           31.99m\n",
      "       179           1.0275           31.77m\n",
      "       180           1.0257           31.56m\n",
      "       181           1.0222           31.33m\n",
      "       182           1.0197           31.11m\n",
      "       183           1.0171           30.88m\n",
      "       184           1.0145           30.66m\n",
      "       185           1.0111           30.43m\n",
      "       186           1.0087           30.21m\n",
      "       187           1.0017           29.98m\n",
      "       188           0.9972           29.77m\n",
      "       189           0.9945           29.55m\n",
      "       190           0.9923           29.33m\n",
      "       191           0.9888           29.11m\n",
      "       192           0.9871           28.90m\n",
      "       193           0.9846           28.68m\n",
      "       194           0.9817           28.47m\n",
      "       195           0.9793           28.26m\n",
      "       196           0.9750           28.05m\n",
      "       197           0.9724           27.84m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       198           0.9706           27.63m\n",
      "       199           0.9687           27.42m\n",
      "       200           0.9658           27.21m\n",
      "       201           0.9637           27.01m\n",
      "       202           0.9608           26.80m\n",
      "       203           0.9584           26.59m\n",
      "       204           0.9569           26.38m\n",
      "       205           0.9537           26.18m\n",
      "       206           0.9512           25.98m\n",
      "       207           0.9481           25.77m\n",
      "       208           0.9433           25.58m\n",
      "       209           0.9403           25.38m\n",
      "       210           0.9377           25.19m\n",
      "       211           0.9364           25.03m\n",
      "       212           0.9330           24.86m\n",
      "       213           0.9313           24.66m\n",
      "       214           0.9293           24.46m\n",
      "       215           0.9267           24.25m\n",
      "       216           0.9248           24.05m\n",
      "       217           0.9221           23.85m\n",
      "       218           0.9193           23.65m\n",
      "       219           0.9175           23.46m\n",
      "       220           0.9149           23.26m\n",
      "       221           0.9128           23.06m\n",
      "       222           0.9103           22.86m\n",
      "       223           0.9083           22.67m\n",
      "       224           0.9056           22.47m\n",
      "       225           0.9026           22.27m\n",
      "       226           0.9006           22.07m\n",
      "       227           0.8983           21.88m\n",
      "       228           0.8957           21.68m\n",
      "       229           0.8934           21.49m\n",
      "       230           0.8915           21.29m\n",
      "       231           0.8892           21.10m\n",
      "       232           0.8871           20.90m\n",
      "       233           0.8854           20.71m\n",
      "       234           0.8825           20.52m\n",
      "       235           0.8810           20.33m\n",
      "       236           0.8789           20.13m\n",
      "       237           0.8767           19.94m\n",
      "       238           0.8758           19.75m\n",
      "       239           0.8737           19.56m\n",
      "       240           0.8711           19.37m\n",
      "       241           0.8694           19.18m\n",
      "       242           0.8677           18.99m\n",
      "       243           0.8659           18.80m\n",
      "       244           0.8642           18.61m\n",
      "       245           0.8576           18.42m\n",
      "       246           0.8542           18.24m\n",
      "       247           0.8505           18.05m\n",
      "       248           0.8462           17.86m\n",
      "       249           0.8446           17.67m\n",
      "       250           0.8426           17.48m\n",
      "       251           0.8404           17.30m\n",
      "       252           0.8381           17.11m\n",
      "       253           0.8369           16.93m\n",
      "       254           0.8351           16.74m\n",
      "       255           0.8327           16.56m\n",
      "       256           0.8301           16.37m\n",
      "       257           0.8291           16.19m\n",
      "       258           0.8273           16.00m\n",
      "       259           0.8264           15.82m\n",
      "       260           0.8243           15.63m\n",
      "       261           0.8226           15.45m\n",
      "       262           0.8213           15.27m\n",
      "       263           0.8196           15.08m\n",
      "       264           0.8179           14.90m\n",
      "       265           0.8160           14.72m\n",
      "       266           0.8127           14.54m\n",
      "       267           0.8097           14.35m\n",
      "       268           0.8080           14.17m\n",
      "       269           0.8067           13.99m\n",
      "       270           0.8048           13.81m\n",
      "       271           0.8024           13.63m\n",
      "       272           0.8005           13.45m\n",
      "       273           0.7995           13.27m\n",
      "       274           0.7983           13.09m\n",
      "       275           0.7972           12.91m\n",
      "       276           0.7953           12.73m\n",
      "       277           0.7938           12.55m\n",
      "       278           0.7923           12.37m\n",
      "       279           0.7910           12.20m\n",
      "       280           0.7896           12.02m\n",
      "       281           0.7878           11.84m\n",
      "       282           0.7863           11.66m\n",
      "       283           0.7843           11.48m\n",
      "       284           0.7831           11.31m\n",
      "       285           0.7822           11.13m\n",
      "       286           0.7777           10.95m\n",
      "       287           0.7756           10.78m\n",
      "       288           0.7741           10.60m\n",
      "       289           0.7726           10.43m\n",
      "       290           0.7713           10.25m\n",
      "       291           0.7704           10.07m\n",
      "       292           0.7690            9.90m\n",
      "       293           0.7671            9.72m\n",
      "       294           0.7653            9.55m\n",
      "       295           0.7616            9.39m\n",
      "       296           0.7596            9.22m\n",
      "       297           0.7586            9.06m\n",
      "       298           0.7578            8.90m\n",
      "       299           0.7565            8.74m\n",
      "       300           0.7553            8.58m\n",
      "       301           0.7538            8.42m\n",
      "       302           0.7523            8.25m\n",
      "       303           0.7514            8.09m\n",
      "       304           0.7507            7.93m\n",
      "       305           0.7488            7.76m\n",
      "       306           0.7474            7.60m\n",
      "       307           0.7459            7.43m\n",
      "       308           0.7446            7.27m\n",
      "       309           0.7430            7.10m\n",
      "       310           0.7412            6.93m\n",
      "       311           0.7369            6.77m\n",
      "       312           0.7352            6.60m\n",
      "       313           0.7330            6.43m\n",
      "       314           0.7312            6.26m\n",
      "       315           0.7301            6.09m\n",
      "       316           0.7288            5.92m\n",
      "       317           0.7281            5.75m\n",
      "       318           0.7270            5.58m\n",
      "       319           0.7235            5.41m\n",
      "       320           0.7217            5.24m\n",
      "       321           0.7206            5.07m\n",
      "       322           0.7192            4.90m\n",
      "       323           0.7177            4.73m\n",
      "       324           0.7166            4.56m\n",
      "       325           0.7154            4.39m\n",
      "       326           0.7146            4.21m\n",
      "       327           0.7133            4.04m\n",
      "       328           0.7121            3.87m\n",
      "       329           0.7114            3.70m\n",
      "       330           0.7096            3.52m\n",
      "       331           0.7079            3.35m\n",
      "       332           0.7052            3.18m\n",
      "       333           0.7038            3.00m\n",
      "       334           0.7026            2.83m\n",
      "       335           0.7010            2.65m\n",
      "       336           0.6996            2.48m\n",
      "       337           0.6985            2.30m\n",
      "       338           0.6971            2.13m\n",
      "       339           0.6960            1.95m\n",
      "       340           0.6952            1.78m\n",
      "       341           0.6939            1.60m\n",
      "       342           0.6911            1.42m\n",
      "       343           0.6899            1.25m\n",
      "       344           0.6890            1.07m\n",
      "       345           0.6872           53.45s\n",
      "       346           0.6864           42.79s\n",
      "       347           0.6859           32.12s\n",
      "       348           0.6846           21.44s\n",
      "       349           0.6833           10.73s\n",
      "       350           0.6823            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1          41.7745           75.24m\n",
      "         2          35.3648           75.30m\n",
      "         3          30.0684           75.08m\n",
      "         4          25.6457           74.77m\n",
      "         5          22.0197           74.54m\n",
      "         6          19.0001           73.99m\n",
      "         7          16.4988           73.67m\n",
      "         8          14.4336           73.55m\n",
      "         9          12.6703           73.63m\n",
      "        10          11.1969           73.46m\n",
      "        11           9.9335           73.05m\n",
      "        12           8.9158           72.81m\n",
      "        13           8.0454           72.69m\n",
      "        14           7.3038           72.52m\n",
      "        15           6.6811           72.42m\n",
      "        16           6.1549           72.27m\n",
      "        17           5.6997           72.07m\n",
      "        18           5.2888           71.83m\n",
      "        19           4.9487           71.51m\n",
      "        20           4.6445           71.28m\n",
      "        21           4.3825           71.15m\n",
      "        22           4.1452           70.86m\n",
      "        23           3.9472           69.67m\n",
      "        24           3.7581           68.55m\n",
      "        25           3.5855           67.48m\n",
      "        26           3.4433           66.53m\n",
      "        27           3.3048           65.60m\n",
      "        28           3.1881           64.75m\n",
      "        29           3.0736           64.03m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        30           2.9727           63.29m\n",
      "        31           2.8817           62.59m\n",
      "        32           2.8030           61.94m\n",
      "        33           2.7126           61.26m\n",
      "        34           2.6332           60.68m\n",
      "        35           2.5632           60.41m\n",
      "        36           2.5045           60.42m\n",
      "        37           2.4535           59.94m\n",
      "        38           2.4018           59.41m\n",
      "        39           2.3465           58.90m\n",
      "        40           2.2914           58.37m\n",
      "        41           2.2526           57.91m\n",
      "        42           2.2089           57.43m\n",
      "        43           2.1750           57.01m\n",
      "        44           2.1420           56.56m\n",
      "        45           2.1144           56.17m\n",
      "        46           2.0857           55.76m\n",
      "        47           2.0566           55.32m\n",
      "        48           2.0292           54.94m\n",
      "        49           2.0002           54.53m\n",
      "        50           1.9770           54.16m\n",
      "        51           1.9449           53.78m\n",
      "        52           1.9208           53.41m\n",
      "        53           1.8999           53.06m\n",
      "        54           1.8732           52.71m\n",
      "        55           1.8563           52.38m\n",
      "        56           1.8387           52.04m\n",
      "        57           1.8218           51.71m\n",
      "        58           1.8065           51.39m\n",
      "        59           1.7930           51.10m\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(gbr, train.values, y_train, cv=5, scoring='neg_mean_squared_error')#0.673187 (0.066807)\n",
    "print(\"gradient boosting regressor score: {:4f} ({:4f})\".format(results.mean(), results.std()))\n",
    "\n",
    "results = cross_val_score(adb, train.values, y_train, cv=5, scoring='neg_mean_squared_error')#-0.373219 (0.343094)\n",
    "print(\"adboost regressor score: {:4f} ({:4f})\".format(results.mean(), results.std()))\n",
    "\n",
    "results = cross_val_score(bag, train.values, y_train, cv=5, scoring='neg_mean_squared_error')#0.567878 (0.058145)\n",
    "print(\"bagging regressor score: {:4f} ({:4f})\".format(results.mean(), results.std()))\n",
    "\n",
    "results = cross_val_score(nn, train.values, y_train, cv=5, scoring='neg_mean_squared_error')#-17.162579 (34.638616)\n",
    "print(\"neural network score: {:4f} ({:4f})\".format(results.mean(), results.std()))\n",
    "\n",
    "results = cross_val_score(rf, train.values, y_train, cv=5, scoring='neg_mean_squared_error')#0.518(0.057)\n",
    "print(\"RandomForest score: {:4f} ({:4f})\".format(results.mean(), results.std()))\n",
    "\n",
    "results = cross_val_score(et, train.values, y_train, cv=5, scoring='neg_mean_squared_error')#0.617(0.05)\n",
    "print(\"ExtraTrees score: {:4f} ({:4f})\".format(results.mean(), results.std()))\n",
    "\n",
    "results = cross_val_score(xgbm, train.values, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "print(\"XGBoost score: {:4f} ({:4f})\".format(results.mean(), results.std()))#0.658(0.065)\n",
    "\n",
    "\n",
    "results = cross_val_score(svm, train.values, y_train, cv=5, scoring='neg_mean_squared_error')#\n",
    "print(\"SVM score: {:4f} ({:4f})\".format(results.mean(), results.std()))\n",
    "\n",
    "\n",
    "stack_with_feats = StackingCVRegressorRetrained((nn, rf, et), cat, use_features_in_secondary=True)\n",
    "\n",
    "results = cross_val_score(stack_with_feats, train.values, y_train, cv=5, scoring='neg_mean_squared_error')#en: 0.674925(0.06)\n",
    "print(\"Stacking (with primary feats) score: {:4f} ({:4f})\".format(results.mean(), results.std()))\n",
    "#Stacking (with primary feats) nn score: 0.674353 (0.059497)\n",
    "\n",
    "stack_with_feats_2 = StackingCVRegressorRetrained((bag, gbr, rf, et), cat, use_features_in_secondary=True)   \n",
    "results = cross_val_score(stack_with_feats_2, train.values, y_train, cv=5, scoring='neg_mean_squared_error')#0.675728 (0.066580)\n",
    "print(\"Stacking (with primary feats) 2 score: {:4f} ({:4f})\".format(results.mean(), results.std()))    \n",
    "\n",
    "stack_with_feats_2 = StackingCVRegressorRetrained((gbr, et), cat, use_features_in_secondary=True)  \n",
    "\n",
    "results = cross_val_score(stack_with_feats_2, train.values, y_train, cv=5, scoring='neg_mean_squared_error')#0.675728 (0.066580)\n",
    "print(\"Stacking (with primary feats) 2 score: {:4f} ({:4f})\".format(results.mean(), results.std())) \n",
    "\n",
    "stack_with_feats_2 = StackingCVRegressorRetrained([xgbm, gbr], cat, use_features_in_secondary=False)   \n",
    "results = cross_val_score(stack_with_feats_2, train.values, y_train, cv=5, scoring='neg_mean_squared_error')#0.675728 (0.066580)\n",
    "print(\"Stacking (with primary feats) 2 score: {:4f} ({:4f})\".format(results.mean(), results.std()))\n",
    "\n",
    "stack_with_feats_2 = StackingCVRegressorRetrained((bag, cat, rf, et), gbr, use_features_in_secondary=True)\n",
    "\n",
    "stack_with_feats_2 = StackingCVRegressorRetrained([xgbm], cat, use_features_in_secondary=True)#, gbr\n",
    "results = cross_val_score(stack_with_feats_2, train.values, y_train, cv=5, scoring='neg_mean_squared_error')#0.675728 (0.066580)\n",
    "print(\"Stacking (with primary feats) 2 score: {:4f} ({:4f})\".format(results.mean(), results.std()))\n",
    "\n",
    "stack_with_feats_2.fit(train, y_train)\n",
    "\n",
    "y_pred = stack_with_feats_2.predict(test)\n",
    "\n",
    "df = pd.read_csv('./sample_solution.csv')\n",
    "df['contest-tmp2m-14d__tmp2m'] = y_pred\n",
    "df.to_csv('submission_corr_important.csv', index=False)\n",
    "\n",
    "best_df = pd.read_csv('best_sub.csv')\n",
    "y_best = best_df[target[0]].values\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "cos_sim = dot(y_best, s)/(norm(y_best)*norm(s))\n",
    "print(\"cos_sim with best submission:\", cos_sim)\n",
    "\n",
    "stack_res = stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ebbcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "action-env",
   "language": "python",
   "name": "action-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
